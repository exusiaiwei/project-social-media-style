这就是Fitzhugh-Nagumo model
Izhikevich为此模型写的综述，很经典：
 Izhikevich大神的网站
各种模型效率的比较：
程序演示（matlab）： 
这个，有点难度啊，。。。。
以及其他分布式的图形来进行表达，这也是我们辩证思维所根据的事实。有道是量变到质变，没有量的量的描述就无法进行模糊集以及概率的处理。博弈论和运筹学有着相似的处理规则，都需要具有数的概念。
我这里的数不光是数字的数，而且还应该包括模拟量。我们知道数字可以有多种进制，而模拟量就是模无穷大的，二进制是模最小的，他们都是代表着数量关系。不用二进制，不用十进制，不用十六进制，不代表就没有数量，数量是描述世界的一个基本工具。
分段函数，网格计算，都是对非线性事物的一个近似的计算方式，网格图像我们大家都已经可以说都已经在许多地方看见过，可以描述比较复杂的图形，这些都和数的概念有关。
比如一台自动速度控制器，过去用比例微积分控制，现在用模糊控制，甚至用神经网络的。自动速度控制器的任务是保持在负载变化的条件下尽量保持速度不变，比例微积分控制器存在着一定范围的振荡，存在围绕期望值的过冲。而模糊控制器的性能就要好得多，因为模糊控制器是根据速度偏离期望值的大小
以及变化速率的大小来进行输出量的控制的，可以很好的避免过冲和振荡，如果换成控制汽车的方向盘，比例微积分控制器就像一个不会开车的新驾驶员，模糊控制器可以像经验丰富的驾驶员一样的开的稳。
大量的人工智能系统，都离不开量这个概念，运筹学需要计算数量，比如线性规划需要计算，博弈论也需要进行得失大小的计算，没有数量就根本无法计算得失的大小，也就无法进行博弈。就是在老三论也离不开对数的计算，老三论是指:控制论，信息论，博弈论。
对于模糊理论的评价我在第七楼有长篇回复。请移步！
这两段的回复在第八楼。
这贴的回复在第九楼。
这两个回复的回复在第十楼。
此回复的回复在第十一楼。
此贴回复见十二楼。
但是世界是复杂的，存在大量的事物是无法用普通集来进行描述的，比如秃子和非秃子，就不是经纬分明的，一个满头头发的人肯定不是秃子，但是少了一根也不会是秃子，但是一直一根一根的减少，最后一根头发也没有了，这时这个人肯定就是秃子了。
这就是事物连续变化的过程，秃子与非秃子存在一个连续的变化，也就是这个集是存在连续变化的边界，这个边界就是模糊区域。比如我们问一个半秃的人是属于秃子呢还是非秃子，普通集合要么是，要么不是，不存在模棱二可的状态。而模糊集就可以用一到零来进行表达，上面的例子就可以用0.5是秃子，
0.5非秃子，我们还可以用1到0的连续变化来表达秃的是否厉害的量。我们现在已经知道如何用模糊集来表达存在连续变化的概念来，这样一来我们思考问题的能力就变得灵活起来了，思维能力从普通逻辑思维变上升到能够进行辩证思维了。
早期的人工智能，只能进行二值的逻辑思维，不能像人脑那样的进行辩证思维，所以显得非常的死板，不能进行灵活的思考，这就是因为心中无数的关系。
而神经元既可以是一个输入就产生输出也可以所有的输入都满足才产生输出，也可以介于或门和与门之间，而且还可以根据各个输入的权重来产生是否输出，这样一来神经元处理问题就要灵活的多，可以处理各种模糊集的问题。
也就是神经元既可以处理二值逻辑的问题，又可以处理模糊集的问题。而且每一个神经元都具有相同的算法，因此编程也是大家相同的，只是神经元的输入端多少的不同以及各个输入端的权重不同。
接下来我们探讨一下神经元是如何进行模糊处理的，我们大家知道一个神经元通过学习，它的各个输入端的权重是不同的，这个不同就是因为输入端与这个神经元所代表的集关联强度不同，关联度高的权重就大，神经元就容易响应，关联度小的神经元就不容易响应。
而且我们还知道神经元是可以调阀值的，我们可以通过调节阀值的大小来调节神经元的保守度，这个保守度可以通过控制论的方式来进行调节，使得神经元网络具有非常强大的灵活性。
我们大家都已经知道了模糊集是什么一回事了，因此就能够很好的理解，神经元这个计算单元的功能是什么样的，也可以看出神经元网络为何会有如此强大的计算功能或叫做处理信息的能力也可。
各个投票人的具体票数是不同的，根据权重不同，权重大的相当于票数多，权重小的相当于权重小。如果我们用二值逻辑器件来构成这样一个投票器，大家思考一下，该如何设计？
什么是二值逻辑器件，计算机是不是？
此贴及此帖的各个回复的回复见第十六楼。
既然题目是智能与数学。我就再加一句。数学是智能产物，是智能结晶
此贴的回复见第十九楼。
此贴的回复见第二十楼。
这次我们有些一致了。
<<学前心理学>>有介绍无条件反射和条件反射的学习。懂神经网络的可以去看看。主要是介绍0-6岁儿童的各能力发展过程和功能表现。对于建立一个人工神经网络的功能发展的路线计划，非常有启发。
（注：这里已经不是数学了，故不再另楼回复）在模拟人类智能的系统里，条件反射根本摆不上桌面。想不到直到现在，你连我搞的不是条件反射都不知道。你还反驳我什么？请问你知道什么是反射么？你知道条件反射与反射出多少么？真不可理喻！
反射是神经间的联系，人工神经网络理论中神经元通过神经突触的联系都属于反射。条件反射仅仅是巴甫洛夫的一个生物实验，它验证了条件刺激通过非条件刺激与非条件反射建立的联系。巴甫洛夫把这种经训练建立的联系叫做条件反射。同样有反射两个字，它们各自说的事情相差很多。
我提出了“反射算法”。但是从来不提什么“条件反射算法”。因为反射是智能的一个基础，而条件反射与智能的关系很少。反射与神经突触构建的都是神经网络，不同的是反射不采用任何数学模型，人工神经网络则投靠了数学模型。“反射算法”利用一个表格，反映神经间联系。（未完）
（接上）而人工神经网络则用信息传输和神经元的阀值的数学模型构建神经网络。两者相比，同是构建神经网络，“反射算法”先有智能后有数学。“人工神经网络算法”则是先使用数字数学，后产生智能。显然，“反射算法”更加接近人类智能的实际。谁优谁劣，一目了然。（完）
由于fjg5610先生错吧条件反射当成反射，这个帖子已经错得离谱了。就没必要回复了。
由儿童心理学考虑智能的发展，这很靠谱。但是还是不要受fjg5610先生的错误引导，把条件反射与“反射算法”混为一谈。
由那本书的意思，条件反射就是个行动知识：特定条件发生》相应动作或不行动。按照实验者命令做到规定动作就是条件反射。至于反射算法没了解。
条件反射在形成行动上有少许作用，但是对智能的形成没什么意义。不去管这个用处不大的东西了。
是的，但是这代表一个知识点的运行机制，可以凡化和分化，可以改变，再回忆，正负迁移机制，消退(忘记)。
智能就是通过世界上的万事万物存在的相关性来预测的，也就是通过外延的方式来表现智能的，这些方式都不需要，真不知道这种智能是如何的智能。条件反射是神经元网络学习的结果，这个学习方式也不需要。我们可以不要下面的楼层建造一个空中大楼，这就是老rui的想法。
条件反射是神经网络学习的结果，使得神经元网络产生了联想，动物和人脑的学习本质就是会产生各种的联想，联想到的本质就是事物与事物间在脑中产生了一定的关联，也就是神经元之间加强了联系，连接不断的加强最后产生了A联想到B结果是会产生望梅止渴
是不可比性。在认知事物的角度看，如果说感知是沙粒，条件反射就是认知事物的砖头--一些沙粒的固定组合，对事物环境的全面认知就是一幅墙---各种各样的认知知识描述了事物。这些沙粒砖头墙壁都是认知能力的质变的表现，孩子只能从感知开始，逐步发展出抽象逻辑思维，难点是如何发展。
到这里，fjg5610先生已经完全偏离了“智能与数学”这个讨论的课题了。非主要课题不是不可以讨论，但是要一个一个问题的说，才能辨明是非。
在fjg5610先生写“我们大家都知道……”时，不知他想过没有，他的这些议论是从哪儿来的？有多少根据？这些问题不搞清楚，还怎么讨论呢？
“真不知道这种智能是如何的智能”这才是 fjg5610先生的心里话，因为他本人的智能系统里，还容不下他宣卖的理论以外的东西。不知道就是不知道，为什么要假装知道反对其它理论呢？
“条件反射是神经网络学习的结果，……” fjg5610先生的灵感来了，接着写出如此惊艳的议论。有句话怎么说来着：想象很丰满，现实很骨感。你能用现实证明你的这番想象么？如果不能，丰满的想象就只能面对骨感的现实哭泣了！
说得对！
此话怎么讲？我第一次听说数学还有不同的定义。
不知道你所说的数现象如何定义，在一些哲学观中认为一切皆数，在这样的认识观下，你所说的数现象就是数学。人的意识通过区分形成不同物的观念，“区分”就是一个符号化的过程，是阴阳之分，0、1之分。
您好，许多年前给您发过一封邮件，没有回音。 从您的思路来看，感觉您应该是不会写程序，是这样的吗？
照你说来，对数还真是有不同的定义。领教了！不过，你后来说的“数现象就是数学”还是有问题。一切皆为数不等于一切皆相等。数学、数现象、狗皆为数，由此不能推论说数学＝数现象＝狗。
“人的意识通过区分形成不同物的观念，“区分”就是一个符号化的过程，是阴阳之分，0、1之分。”这些议论已经非我智力范围所及，不做回复。
我可以使用很多种语言写程序，但因为不是专业程序员，没写过大程序。没有把想法编成大的系统程序的经验。
你还没有定义什么是数现象，人们是如何认识到数现象的？ 我也并没说数学＝数现象＝狗，我认为，一切皆为数可以等价于一切皆为符号，数学就是研究符号逻辑的学问。
建议您讲解的内容，能多配一些图片，这样可能容易理解一些。
“你还没有定义什么是数现象”本来我想回一个定义的，写定义的时候发现势头不对。如果用数定义数现象，恰好无法回答“数是什么？”只好先承认数确实有不同定义（尽管我不同意你的定义）。再考虑数现象能否定义。
“你还没有定义……”我经过考虑，发现任何普遍现象都是一些个别现象的总和，只能用枚举的方式谈论它，不能定义它。数现象也是如此。当我们说到“数现象”时，一定已经给数下了定义。不能再用“数”反过来描述它的源头。只能把“数现象”看成一个整体符号，用一些的数现象描述它。
“一切皆为符号”我想，你也一定不反对“数现象仅仅是一个无定义的符号”这个说法。从这个说法看“数现象”的数与“数学”“数字”的数暂时无关。而在定义数字、数学时，是用数现象的数定义数学，定义数字。
（接上）如此几个概念的逻辑关系是这样：１、数现象：无定义符号，由离散数现象和连续数现象等大量客观现象组成。２、数字（定义）：反映数现象的符号群体。３、数学（定义）：研究数现象和其它符号现象的学科。如此构成一个合乎逻辑的概念体系。
“数学就是研究符号逻辑的学问。”我的定义与你的定义很类似。
比如……？？？
我认为，谁走到最后，谁才走得最好。我反对“人工神经网络是人工智能最好的出路”的观点，但是不反对“人工神经网络可以为人工智能做点事”的观点。谁能做什么，就去做什么好了。
看上去我很主张息事宁人。但是事关是非曲直的事情，还是要讨论清楚，一丝不苟。比如这里的数学与智能的关系。关键问题是，人们如果承认智能产生数学可以作为模拟智能的一种基础，我也能够容忍他们的用数学构造智能的想法。不能容忍的是：一见不靠数学构建智能，就欲剿灭之而后快，唯他一家独大。
如果人工智能的载体必须是计算机，数学还是需要的，只是未必很复杂。过年读了霍金斯的《人工智能的未来》，里面有个观点很有意思，人的各个感官接收到的数据都是同一种，所以大脑对外界输入的处理也应该是统一的算法，另外提到人类的智能核心就是学习＋预测
听起来很像朴素贝叶斯算法，个人觉得贝叶斯或许才是人工智能的真正算法
听起来很像朴素贝叶斯算法，个人觉得贝叶斯或许才是人工智能的真正算法
需要数学与统一的算法完全是两回事，怎么说成因果关系呢？
你终于开始就对方的想法讨论问题了。你提出的问题也很重要，但是很好解决。我的着眼点还是：先看看人脑是怎样做到的，再说怎么解决。由于下一楼你仍旧在议论快速查找的问题，进一步回复放在下一楼。
“贝叶斯算法……”不是有意扫你的兴，这个贝叶斯算法还是个傻帽算法。它回避了对人脑分类方法的研究，转用统计算法，无疑增加了该类算法的不稳定和不准确性，甚至还具有不确定性。（未完）
（接上）如果采用离散的分类算法，就不会有这“三性”。该算法由分析操作、找特征操作、综合操作组成。先由分析操作把分类对象各自拆解开，然后由找特征操作从拆解的各个对象中找出共同点。最后由综合操作把具有相同特征的对象整合为一类。这个分类操作一次可以分出多个类。（未完）
（接上）离散的分类操作不用任何数学方法。它可以对文字型、数字型、图像型、其它信息符号型等多类型信息进行分类。而贝叶斯算法只能对数据型信息分类（其它型要转化为数据型）。后者能分类的面非常窄。（未完）
（接上）由于离散的分类操作对象类型丰富，分类步骤明晰，因此它的操作结果是稳定的。由于分类依据是对象的特征，与人脑分类依据一致，因此分类是准确的。由于分类依据具有确定性，因此分类结果是确定的。显然，它没有贝叶斯算法的“三性”。谁更好？显然是一目了然的。（完）
前面我回复你，先要看看人脑是怎么做的？人脑不会瞎查找，也不会去搞组合。它是按照所需资料的特征查找的。如何做到这一点？首先从人脑的记忆结构下手。人脑记忆的东西不是胡乱存放的，而是有次序的，有标志的（详见我关于记忆的讨论）。这与计算机的目录有些相似。（未完）
我觉得你对数现象的描述不够深入和基本，离散和连续都是上层的概念了。我的认同的观点是最基本的符号只有两个，可以名有、无，也可以名我、非我，或者简化为0、1.当使用这两个基本符号构建出第三个符号时，量的概念产生了，有了量就能定义次序，万物有序而生。
（接上）但是可惜的是，计算机读不懂目录。而智能系统不同，它有言语活动机制，能够读懂大脑里的存放标志。智能系统还有思维机制，它能够分析出查找资料的快捷方式。这一切都比模糊集合、统计等方法更快捷、更准确、更容易成功。（完）
你曾说“一切皆是数等同于一切皆是符号”。难道你不能把“离散”“连续”都看成符号，而不是概念吗？离散不过是代表“一个一个分开”的符号，连续不过是代表“连在一起分不开”的符号。何上层概念之有？至于你底下的宏论，非我智力所及，不予回复。
人类的行为本来就具有模糊和不确定的特征，如果人工智能的输出是唯一解，那么就不符合人类的特征了。另外贝叶斯只是统计样本的数量，对样本本身并不要求转换成数字型
“人类的行为本来就具有模糊和不确定的特征”任何事情都是相对的。如果人类从来不可能有确定性，那么确定性这个概念就不会出现。人类还是追求确定性的。比如，老师在讲台上问：１＋１等于几，他一定不允许学生回答出几十种不同的答案。人的行为中确定性还是有的。（未完）
（接上）一些所谓的专家，解决不了智能的确定性问题，就以“有不确定性”遮羞，其实是懦夫行为。智能活动是泾渭分明的，确定性行为就是确定的，不确定性行为就是不确定的。用一个掩盖另一个是错误的！你可别上他们的当啊！！（完）
“贝叶斯只是统计样本的数量，”把样本变成样本数量就是向数字转型。不然呢？谁也不会蠢到把文字样本都用数码来写，就是写了，对于统计也无济于事呀。问题在于，只统计样本数量的结果，就是看不见样本的本质特征了，不按本质特征分类，就像是在糊弄小孩。别信他们的！！
不确定性是指运算结果用概率表示，也就是说不会出现唯一解，比如脚下有块石头，大脑可以通过已有样本得出以下3个结论：跨过去的成功概率90%，跳过去的成功概率8%，爬过去的成功概率2%，结论就是选择跨过去
“不确定性是指运算结果用概率表示”既然概率只能解决不确定性问题，而解决不了人类的确定行为问题，那就表明概率统计与人类行为中的确定性行为不符，它也就没有资格用来模拟人类智能。它应该与大脑行为毫无关联，又何必让它来如此糟蹋大脑呢？
人类有什么行为是确定性的？1＋1等于几也是存在不同答案的。从某些角度讲，不确定的存在是人类不断进化的根源，起码提供了纠错的功能，每一次的错误结果都会帮助大脑重新生成新的概率分布
“1＋1等于几也是存在不同答案的”这是典型的赵本山理论，那是玩笑，不能做科学讨论。在算术里１＋１只能等于２。确定的。不能有别的答案的。如果不确定性是人类行为的主流，那你还谈贝叶斯干什么，他也很不确定嘛，是什么东西还说不准呢！你参与讨论，起码你还确定贝叶斯是什么。
“从某些角度讲，不确定的存在是人类不断进化的根源，起码提供了纠错的功能，每一次的错误结果都会帮助大脑重新生成新的概率分布”——你真的确定是你说的这样吗？
二进制的1＋1等于10，玩笑里1个男人+1个女人等于3个人甚至更多，不管这些答案是否符合科学原理，起码大脑是接受和理解这样的答案的，如果人类只接受确定的答案，那人和机器还有什么分别？
另外不确定不代表混乱和无规则，可以把不确定理解为黑白两色之外还有灰色的存在，这个灰色提供了弹性，可以让大脑有学习和进化的可能，刚性的系统是很难进化的
这也是人脑处理信息的特点，可以灵活处理。人工神经元网络在神经元这个方面，可以说是具有充足的证据证明神经元是如何工作的，我们也可以通过数学的方法来进行研究，这就是计算神经学。模糊集不是人脑什么灵机一动想出来的，这都是客观世界的反映，这也是为什么人脑需要对事物进行辩证处理。
人脑辩证处理问题的方式，现在通过模糊数学的方式得到了形式化。人脑不是光会进行普通集的处理，只有普通集的概念。而大量的概念是属于模糊集的，是需要通过辩证处理才能得到较好的效果。中国的知识分子就是思想僵化，思路太狭窄了，而且还不会思考和理解问题，还在闭门造车。
有许多人由于思维的狭窄，认为计算机处理问题不知变通，没有泛化能力，这中想法都是因为认为计算机只能进行普通逻辑问题的处理，而不会辩证的处理问题。其实现在的人工智能早就具有强大的变通能力了，也具有强大的泛化能力了，可以处理没有遇见过的问题，泛化能力和保守度有关。
快出来看看我发的帖子
人脑遇见一个没有学习过的问题，就会通过模糊归类，把问题向已知的相近的集靠拢，这在数学上就是把模糊区域扩大，也就是降低集的保守度，把模糊集的范围进行了扩大。这样新的问题就成了归类到几个相近的集了，这样就可以对问题进行处理了。
现在我们知道泛化的原理了，我们也就可以对机器泛化能力进行设计了，比如在神经元系统中，我们可以通过对神经元的阀值进行降低，这样一来神经元的泛化能力就可以得到加强，保守度越高泛化能力越低，包守度越低泛化能力就越强，调节阀值就是调节保守度。
没学过模糊学，不做评论。人工神经网络只能解决已经出现过的问题，不能处理没有出现过的问题，假如把所有的问题视为一个集合，bp只能处理某个子集，换句话说，bp缺乏预测(泛化)的能力，至少目前没有看到解决方案，不过cnn好像有一定的可能性，总之，bp的核心是随机性，所以个人不看好
汗没有数字怎么处理量的信息[疑问]
人工智能必然要手把手的教。人其实也是自然界手把手带出来的。一个道理。不能看低了“人工”的作用和重要。
其他你说的我很赞同
这就看怎么去理解”教“了，是谁在教，在教谁的问题。这个又扯远了，按照我的理解”人本身也是人工智能产物“。但这么说会把很多人辛辛苦苦建立起来的认知搅浑。[呵呵]
要知道，大自然还是物理学家、化学家、生物学家、法官、政治家、厨师……等等等等，姑且我们还是称之为上帝好了。[呵呵]
如果你的大脑没有确定性，那你说的“二进制的1＋1等于10”也是不确定的，应该说成“不确定二进制的1＋1是不是等于10”才符合你的论点。因为你的大脑里确定“二进制的1＋1等于10”，你才用作例证反驳我。足见你的大脑就存在很多确定性的答案。不要“忘我”地进行争论。
在描述规律上，数学也有烦恼的时候，比如自然语言描述语境类的规律。自然语言也不是万能的，比如对只能意会不能言传之类的规律的描述。那么有通吃的么？当然有，copy ，用同样的资源及结构去描述对象，带出的就不是数学问题了。如果有一天，有人在实验室用神经干细胞及外围硬件搭建了一个智能体，
并教会了它思考，那么我也认为这是个人工智能。再进一步，XXOO出来的也是人工智能[笑眼]
“不管这些答案是否符合科学原理，起码大脑是接受和理解这样的答案的，如果人类只接受确定的答案，那人和机器还有什么分别？”你还在继续忘我地说，你能确定你说的话不变么，如果你不确定，争论作甚？如果有确定性，你就是自打嘴巴！！知道理发师悖论么？你就是这样。
所以，我把人工智能与智能也混为一谈了。
因为非要给智能体贴个出生证很是无语，是为搞阶级斗争用的么？
扯的太远了[狂汗]
你过年好！
只能会意不能言传，就是因为语言传递的信息是模糊的，不存在像图那样的详细信息，真是因为普通语言存在强模糊性，因此用普通语言配合数学来表达就会好的多，如果还配合图形来表达，那么模糊性就可以更小。
如果地球灭亡了，人类又没能侥幸逃出劫难，那么在太阳系还有大自然，而再没有了数学家、物理学家、化学家、生物学家、法官、政治家、厨师等等。大自然就是大自然，人类智能就是人类智能。没办法！也许一切会恢复如初，新的人类被涌现，新智能又创造出数学、物理、化学……自然崇拜并不是什么好事。
你曾经想参与讨论思维，现在讨论已经开始。《那些计算机不能进行的操作》
“没有数字怎么处理量的信息”当然不行！可是我们讨论的是“没有数学能不能构建强人工智能”。而不是如何处理量的信息。
你用什么能力发展出数字能力也就是处理量信息的能力
老rui的想法就是把一切推到从来，让智能重新进行演化，从具有活性的分子开始演化，再产生活的细胞，产生多细胞生物，然后通过亿万年的演化智能就产生了，智能从低级到高级的演化过程也自然的产生了，这个过程完全可以不需要人的数学知识。
自然语言也有很多精准的词汇，数其实是它的子集。
再在这个基础上通过自然过程产生人工智能，这个还是人工智能吗？上帝是懂数学的，因此创造了智能。可是人却不懂数学，因此也就无法创造人工智能了。
请看本主题２９、３０、３１、３８楼的帖子《模拟智能产生数学程序》还未发完，以后接着发。
“老rui的想法就是把一切推倒从来……”你终于明白了一些了。但不是推倒重来，而是从那时开始考察，找出智能产生的原因。我已经找到了，并利用它编写程序，因此我可以鄙视所谓的数学方法编写智能程序。
“这个还是人工智能吗？”当然是人工智能了！因为硬件是人工的，软件也是人工的，是以计算机结构为基础、以计算机程序为基础的系统。上帝根本不存在，他什么也不会创造，一切都要依靠人类自己的努力。
我专门学过模糊数学，不过不看好它半途而废了。我认为它解决不了根本问题，是个折中的法子，但不排除有人能将它走通（殊途同归）。
“减少普通语言的模糊性”用统计和模糊集减少语言的模糊性？没发烧吧？
我倒是把模糊数学学完了，但是我也不看好它。
喂，你怎么不说混沌现象中的蝴蝶效应呢？讨论科学，可不带这么各取所需的。
如果你认为你的思路是对的可以好好讨论，不要为了打败对方而辩论，人工智能还没有真正实现出来，每个人都可以有自己的思路，不可能你的就一定对，别人的也一样，要懂得尊重不同意见
上帝当然是个比喻，比喻一切自然规律的存在性，这个规律可以包括非常广的事物，比如物理规律，数学规律等等规律，也可以说一切的一切都是上帝创造的，因此也可以说上帝是懂这些规律的，问题是这些规律不是人创造的，因此人需要了解这些规律，再把这些规律用符号来进行表达。
“可以好好讨论”这里讨论的是《数学与智能》，讨论别的内容，我已经有太多的主题了。
换句话讲，大道至简，再从简到繁，之间可以有各种程度（或层级）的描述，特意的夸大某一层的作用是容易产生诟病的，除非你能将它在其他层中的映射都补齐，才能升华为大道，也就是说，到那时你说数学就是自然，我也不会说它是错的，不就是一个称谓么，只要它足够胖就行。[呵呵]
获得外部信息谈何容易！机器能识别出物体嘛！？
“上帝当然”……离散符号难道不是符号？符号逻辑（数理逻辑）也全用的是离散符号啊。
以前说过基于语言的思维，还是思维产生的语言（数学也是一种语言）。别弄颠倒了。
通过研究语言去产生思维，这是本末倒置的法子，所以我不看好搞语义的，还是那句话，除非你能把它做胖，语素分解到神经元的级别，否则脑残是一定的。自然语言这样，数学语言更是如此，但它有它的好处——效率。它可以极大的缩小自然进化的开销，前提是你用数学筛出的是金，而不是一场空。
你不了解模糊集，如何会知道该如何处理语言的模糊性 。概率和模糊集，我们叫做不确定性，这里可以用可能性多大与概率挂钩，与某集合的相关性有多大，来与模糊集挂钩。
蝴蝶效应是个比喻，这是需要不断的进行放大，而且边界的约束也要可以容许这种几乎是无穷大的放大，也就是不存在条件约束的限制。
“机器能识别出物体嘛！？”用模拟感觉就可以识别。
其实这个现象通过线性放大，也是可以产生所谓的蝴蝶效应的，只是这个效应比较容易知道将会在何处产生一场风暴。
“我们叫做不确定性，”你也来不确定性了。那你现在的主张是确定性的主张，还是不确定的主张？如果连你自己对自己说的都属于不确定性，那你还主张它干什么？任一切不确定下去，还要构造智能干什么？
模拟感觉谈何容易！？
因为你没有理解模糊集的精粹，模糊集的精粹就是把人脑辩证处理问题的方式得到了形式化。所以我们把用模糊数学处理问题的方式叫做仿人智能，把模糊控制器叫做仿人智能控制器。
智能不可能放任模糊，放任概率，放任混沌，放任不确定。智能的产生就是要结束一切模糊、混沌、不确定、概率。让一切都变得清晰、有组织、确定、精确起来。你曾经说我要推倒重来，从模糊、混沌、不确定、概率出发更是在推倒重来。后退到由无序到有序的自组织过程中去。
“蝴蝶效应是个比喻”但是它针对的是，如果一个复杂系统运行中受稍许影响，就会产生差之毫厘、失之千里的结果。应用于智能，就是说如果从混沌状态考察智能，可能它不知会发展成什么。看来你没学过混沌理论！
“以前说过基于语言的思维”那是说基于语言编写模拟思维程序，而不是说基于语言研究思维。系统的内部信息均是思维处理对象，怎么可能只基于语言去研究它？
“通过研究语言去产生思维，这是本末倒置的法子”你说的是对的，但是我还没有看到有人去那样研究。
不必线性放大，混沌理论也会知道结果如何。因为混沌系统自组织过程中有一些吸引子，系统的状态会自动向吸引子凝聚。
“模拟感觉谈何容易！？”按目前的数学处理方式的确很难。但是用离散编程法的模式识别和特征识别，很容易解决。
蝴蝶效应指的是，初始条件微小的不同，结果会产生非常大的不一样，这就是不可预知的原因。有道是，马钉断，马蹄折，将军摔，战役败，国家完。一根钉马掌的钉子断了，结果引起了马蹄折断了，引起骑在马上的将军摔死了或者不能指挥打仗了，结果是战役失败了，国家给敌人占领了。
处理方式的形式化，决定了其应用的局限性，形式化的特点是高效，缺点是死板，这和智能的普适性、灵活性是背道而驰的，相反，普适与灵活中可以生成（沉淀）出形式化，反之则几乎不可能成立。
就说模拟视觉吧，你什么算法[疑问]，
没见过啊，某研究院所的科研成果，说白了就一聊天机器人，哈哈，逗乐子还行。
拜托，融会贯通一下，蝴蝶效应、测不准、马失前蹄……其实都是现象，也都是应用，是什么的应用呢？有人用数学描述出来了么？回头找个活体神经细胞痛“打”它，看看有没有神经效应。
那么灵光一现、一念之差是不是这种效应的前奏呢
我一看“表现”就会联想到委屈、迎合等词汇。那么灵活性的代价是不是大了些。不过还好你把形式化整胖了。控制一些变量可以提高其灵活性，谁去控制？谁去触发它，是不是说只有加上人，这个系统才具有了灵活性。
留个邮箱地址，过两天给你发一个细致一些的模式识别算法和特征识别算法。
“就一聊天机器人”是预先确定了应答方式的那种把？噢，可能还复杂一些，给定一些心理知识库，根据对方的心理状态做出应答，后者有些像算命的。哈哈。
“蝴蝶效应指的是……”你的蝴蝶效应好像与智能无关？
预测是一种思维操作，很容易搞出来。（见《那些计算机不能进行的操作》）。几天后还有更详细的预测离散算法发出来。
qvzraf@sohu.com
条件反射是通过学习得到的，非条件反射是通过遗传就已经得到了的。因此非条件反射就像rui说的编好的小程序，但是这些小程序需要通过条件反射的学习过程才行，现在的问题是机器是根据什么算法来进行学习的？人脑是靠统计和反馈来进行调节，达到学习的目的。
人脑处理问题的底层是神经元，这些神经元已经是具对不同权重输入进行数学处理的能力了，不要说什么神经元不识数，这个说法本就是不正确的，老rui后面的推导就更错误了，因此数是在人工智能系统中无用的。要知道人脑中的神经元已经是通过我们叫做数学的计算方法在自动处理数据了。
蝴蝶效应指的是，初始数据的微小变化，结果产生的输出就会引起很大的不同，这也说明了人脑为何会对同一件事情，会产生不同的输出，因为人脑处理问题的过程，存在强的非线性现象。
如何控制你可以参考控制论，人的意思部分主要还是用来进行识别和控制的，由于分形结构，因此底层也具有识别和控制能力。
你又陷入你的“人脑是靠统计和反馈来进行调节，”泥潭，因此你无法理解“根据什么算法来进行学习的？”。学习一共有三种离散算法：摸索学习过程、模仿学习过程和内化学习过程。很容易做出程序来的。关键是它们与统计无关。但是它们与反馈有关。
“这些神经元已经是具对不同权重输入进行数学处理的能力了，”这不是生物解剖的结论，而是构建人工神经网络时人为引入的东西，构建者们是懂得数学的，他们用数学方式解读了神经元。建议你好好读一下有关的书，仔细阅读一下细节，不要被自己的错觉迷惑！
“蝴蝶效应指的是，”这回你讲对了。但是它为智能带来的问题是，如果用自然涌现、自然统计、自然模糊去重新模拟智能产生，海量的神经元也会产生蝴蝶效应，最后不仅不会产生智能，还不知会产生什么结果。因此采用智能前的自然涌现、自然统计、自然模糊去产生智能是不可行的。
“统一成条件反射一种形式了”这个统一要不得！！非条件反射是先天的，条件反射式后天的，前者依赖于遗传，后者依赖于训练。后天反射与条件反射也不能统一，条件反射是同时性的，而且是刺激与反应间的，后天反射允许刺激与刺激间建立反射，且允许历时刺激间建立反射。（未完）
（接上） fjg5610先生还分得清条件反射与非条件反射，你这点不如他。但是他分不清后天反射与条件反射。于是他提出不同时的情况如何处理的问题。但他没有认识到多刺激间反射也不是条件反射。引入后天反射的概念，就可以突破同时的限制，突破刺激反应间反射的限制。（未完）

糊评三国志，乱写西游记。
反射这个问题咱们以前讨论过，就不重复讨论了，对它而言分也行合也行，分我可以分的更细，合的话也可以归一，所以不存在沟通困难
相反，您可以试着合一合，如果实在是合不到一起，也别太强求。我鼓励那些能合起来的人，这是个再次抽象升华的机会。
先不说蝴蝶效应、测不准等的数学表达式能否会描述的很清楚，就现象而言，这些效应都是发生在某一个风险临界点上，就象压倒骆驼的最后一根稻草一样。在智能领域中它能解释行为的不可预测性，在微观层面也可以修正神经元对“权重”的认知。而数学为解决这种尴尬，也开始玩儿含糊的概念了，
线性也好离散罢，概率的引入确实焕发了新春，但这是一种技术手段，不是抽象出的数学符号、也不是描述出来的某种自然规律，而是照搬于统计分析的结论。照搬结论和抽象产生有着本质的不同，在设计智能体上，会存在两个极端，
一个需要导师，而且是手把手的教，而且是“5毛钱俩个，1块钱不卖”的那种，另一个极端就是自发的，或者稍微点拨一下的就能继续处理的。所以别争了，先定了设计目的再说。
分形结构是理论上的东西，自然界中通常都是有边界的与源头的，底层底到什么程度是底，当归于无的时候，估计连进化论都帮不上你的忙了。
一个需要导师，而且是手把手的教，结果可能是“5毛钱俩个，1块钱不卖”的那种，另一个极端就是自发的，或者稍微点拨一下的就能继续处理的。所以别争了，先定了设计目的再说。
意识具有唯一性，你要同时考虑两件事就要有两个意识，由于意识承载单元的可塑性，两个意识结构不可能相同，所以意识不能复合。所以多进程意识模式不可能。
在放大不确定性上，很容易联想到某某效应，因为这本身也是合理的。
其实我要解决的问题就一个，如何能赋予智能体”青出于蓝而胜于蓝“的能力。完成智能的闭环，实现自我进化，然后通过这些验证出的规律法则来解决我们人类在进化中所遇到的问题。
你在说苗阜吧？
fjg5610先生终于说了一句如此明白的话：“因此我们需要通过数学手段去减少这个不确定性，”太正确了！！智能的目的也是这样啊。这也是这个主题争论的关键。用数学方式还是用离散算法都不重要，重要的是能不能实现“减少不确定性”。模拟智能的真正目的也就是建立一个能减少不确定性的系统。（未完）
（接上）下面的问题是：fjg5610先生力主的方法能否减少不确定性？什么模糊集、统计等都是在使用不确定性，而非减少不确定性。我们以分类为例，神经网络分类，贝叶斯算法分类，类是分出来了。不确定性减少了那么一点点儿。但是分类依据呢？它给不出来，还给不确定留出很大空间。（未完）
（接上）再看我的离散分类法，它不仅可以一次分出多个类别，而且可以给出分类依据。是一种把不确定性减少至零的分类法。（明天我会在《那些计算机不能进行的操作》主体发出其细节）。显然离散分类法比数学方式分类法减小不确定性效果好。（未完）
（接上）fjg5610先生会想不明白，你说的是真的么？当然。因为我的离散分类法是模仿人脑分类操作设计的算法。而人脑，是一个成熟的减少不确定性的设备。而那些数学方式是用不确定性对付不确定性，稍有成果，但不能彻底消除不确定性。如果效果同样，使用什么方式无所谓。但这里优劣差别如此之大！（完）
怎么可能会出现你说的结果呢。
“在放大……”无限放大会产生无穷大，会导致计算机出现不停机问题。然而人脑设置了“灵感”操作，把无限放大的无穷大激发为灵感的产生，从而巧妙地解决了不停机问题。fjg5610先生不了解灵感的产生原理，编造出一个联想产生灵感的神话！
“实现自我进化”……摸索学习过程算法、模仿学习过程算法解决了系统自我进化问题。系统在学习中会不断产生新的功能（自编程序）。而且，摸索学习过程算法、模仿学习过程算法本身都是一个闭环的反馈网络。
摸索确实是解决进化的方法。不过我不喜欢模仿这个词，象个学徒工，这干的可是抢上帝饭碗的事儿啊，怎么能总站在学徒的位置上研究问题呢[狂汗]
你的离散分类法是如何模仿人的操作的，模仿的是人那个层次的操作。人脑底层处理信息的是神经细胞还是逻辑器件？人脑高层操作能力是否和底层的神经元处理过程有关。你是否是在想，如何才能建造一栋空中楼阁。
减少外界具有嘈杂干扰的信息，我们可以通过滤波的方式，也就是统计法，通过统计把无用信息滤除，凸出有用的信息 。人脑具有辩证处理问题的能力，你用什么方式让机器也具有人脑那样的能力，知道在什么情况下可以进行变通处理问题 从而把理发师悖论去除。
“不过我不喜欢模仿这个词，”不管你喜欢不喜欢，模仿学习都客观存在。而且一个人近四分之一的生命花费在模仿学习上。机器智能如果有了模仿学习能力，其智能进步也会很快。
“是人哪个层次的操作。”我模拟的是可自省范围的大脑操作。分类由两个智能元操作（分析、综合）和一个智能后代操作（找特点操作）共同完成。处理信息既不是神经细胞也不是逻辑器件，而是由ＣＰＵ指令组成的操作小程序。它们是普通计算机的最底层。计算机模拟智能就应该这样模拟。
“建造一栋空中楼阁”如果底下有坚强的支撑，什么地方都可以建楼阁。我的模拟智能以计算机底层为基础，足够坚实，足以支撑智能大厦。在计算机上模拟智能，把底建在神经元上，很多余。那好比你盖楼打地基一定要挖到地心，把楼基建在地心才罢休。那样的底反而不牢靠了。（未完）
（接上）你们的想法很可笑。面对计算机，其底层是ＣＰＵ指令，偏偏幻想着把基础建立在神经元上。哪儿去找神经元？人工编造一些。于是便把幻想当真了，以为自己找到地基了。这不是白日做梦么？模拟的神经网络就是假的神经网络，永远成不了真的。模拟着玩玩可以，作地基用那是虚的。
“减少外界具有嘈杂干扰的信息”如果立足于计算机底层模拟智能，基本上就没有噪声干扰，何需滤除？你又把自己玩晕了吧？
本想让您往前站站，可您跟班跟上瘾了。[狂汗]汗个我自己，站的位置是靠前，但稳不稳只有我自己知道，说什么在别人眼里都感觉像是在吹。[睡觉]
本主题关键是看用数学构筑智能的人是怎么想的，站在我的角度，还真的不知道他们在顽固地想些什么。现在有些收获，对他们有那么一点了解了。至于你，感觉已经不像从前那样执着了，也许这些年把你的锐气磨掉了。
我还是很执着的，只是冲过头了，猛然发现身后没有人跟着，掉头往回走走，顺便拾拾遗，对遇到的人讲讲前面的风景[冷]
万一能碰到几个志同道合的，一起合力回去再上一个台阶岂不更好。
”还真的不知道他们在顽固地想些什么“，他们的情况和你的是一样的，都是在巩固自己跑马圈出来的场子，只是你的场子越界了，哈哈。别介意，这主题是争不出个结果的，但是争论是有好处的。
就觉得你的冲劲不足了么。
“争不出个结果的”结果不重要，重要的是让人们知道还有人在另辟蹊径搞强人工智能。神经网络已经把很多人弄得疯癫了，我又能有多大力气扭转呢？
干嘛非要扭转呢，等着殊途同归吧。我应该算是个搞神经网络的吧，也是搞强智能的，我不需要扭转，前面风景好着呢。
那个特征识别算法是你自己写的？
当然是。
 给我也发一份吧。jianshexilu@163.com。谢谢
还在修改之中，它的这个主题正好帮助我修改。等修改好一定会给你。
原回复有误。我们正在主题《什么能模拟人的感觉！！》详细讨论，讨论后我在定稿。欢迎参与。
你说的是感觉（信息输入）和语言（信息输出），它们的不确定性不是大脑本身的不确定性。它们有不确定性是自然的。而大脑内部对这些信息的处理，正是要消除输入输出信息的不确定性的。
好!
我这里说的都是输入信息存在的不确定性，一个人能够分析出一个个具体事物，就是因为能够从背景中区分出各种物体，声音也是同样存在背景干扰的问题，人的语言的内涵更加具有模糊性，这些处理过程都是大量在非意识的神经网络已经被处理了，否则你根本就无法进行图像处理，声音识别，语言理解。
“在非意识的神经网络已经被处理了，”如果像你说的那样，“说的不严格”“论述的不正确”一类的批评就不会出现。批评是指望他改进，神经网络如果能够自动处理，批评不批评都不会起作用，交给神经网络就齐活了。只有大脑的确定性操作才能处理确定性问题，神经网络是望尘莫及的。
我用了十几楼给出了 fjg5610所问智能如何产生数学。它既是一个程序的流程，又是一篇简短的数学产生史。它充分的阐明了数学是如何被智能构造出来。
“我这里的数不光是数字的数”……数学自然不只是研究数字，但是概率论、模糊数学一定要用到数字。你没有说要用离散数学构建人工智能。如果说了，我们就没有什么分歧了。
智能是被选择出来的，虚数之所以存活是因为电磁学的发展选择了它，很多没有被选择的理论和发明被埋没在历史的尘埃里，就像这篇文章一样。世界上时刻发生着所有的智能非智能，合理非合理，它们都是无意识产生的，是一双有意识的手选择了他们。
你正确地理解了特殊性与统计方法的关系。
用数学方法能够模拟出一些智能现象，但是不可能模拟出全部智能。
同，看的头都大了
哪个大学适合学这个。 山东的。大概六百分到六百三。 自主招生可以上的也算一算。 大神  
回复 小bibibi哥 ：努力往985考吧。当然如果以人工智能为目标的话，数学必须要好，越好越好
做固定逻辑的工具智能需要很好的数学，做类似生物的灵活智能更需要思想理论的基础，数学高中基础足够。
回复 qq24476828 ：这个…你说的类生物的我没接触过，不过不外乎脑科学那些，不过你要建模什么的，没有数学做基础不可能，高等数学，矩阵分析，概率论这些都是最基本的，你要是做优化方向更是需要数学，我是人工智能方向的。
你说的那些高数、矩阵之类是不需要的。脑科学也不多，主要是相似形、分形的方法论和世界观。需要人工优化的只会是工具智能。建一个简单的智能单元和设计迭代、自组织规则就差不多了。我现在用两个端点一条边的单元已推导出特征提取识别分类评价情绪时序记忆常识记忆
回忆意识睡眠做梦，和快乐痛苦奖惩、脑内分泌系统，还需继续解决想像规划的功能
说的对，数学很重要， 数学很重要， 数学很重要～～～ 学人工智能数学很重要
你说的那种太宏观了，我这种层次估计还达不到～～我感觉所有宏观层面的东西，到了实现或建模的部分，没有数学基础是不可能的。
不要感觉玩这个就是玩人工智能，你那种充其量是知识映射
已经比某些光说不做的人好了
我说的那些也是从单元组合的结构中推导出来的，从单元结构到"宏观"功能没有明显界线，是无尺度的。说不需要高等数学不等于不需要数学基础。
额 你所谓的单元是不是类似与深度学习的那种单元？？如果是是深度学习的话，你设计了一种前向计算，难道不需要推导反向计算？？可能你说的人工智能过于偏语义上的人工智能了。就好比 你让TA知道人是猴子变得，然后让它知道A是人，然后让TA说A是猴子变的。这种简单的智能就不需要推导
我设计的是一种波粒二象单元，用波生粒、粒生波、波关联粒的方式组成迭代复杂网络。需要学习母语才能理解语义，一开始只有条件反射。
不错，说说你的进展
目前它还在吸取知识…并没有思考的迹象…原理是通过主动提问和注释提问（在注释中找出不认识的概念提问）进行主动学习，知识来自百度，人工进行检阅。出现思考的判定是提出自行组合或创新的提问
不过…咱对程序进行的轻微的修改，使它“出错”的几率增加（随机改变增加单元之间的连接，系数与两者之间间接连接的单元数成反比）这样或许就能出现所谓的创新了
当然，这只是一个试验。为了证明创新意识的产生并不需要思维。之后咱会再进行情感模拟的试验
哥 ，我咋觉得你说的东西比hinton给的轰动，咱发篇science耍耍吧。。。
你是在嘲笑吧。如你还有点兴趣了解的话过段时间我会发点东西给你。模型设计还没最后完成，纯理论方面你有兴趣可以看我用户名的空间日志。模型设计完才能做软件验证
额 有点小戏弄哈，表介意，不过木有嘲笑的意思。科研的确需要多交流交流的。
可以看下我昨天发的文 目前仍没有解决的问题是几十种化学递质的作用如何在单元模型里自组织实现
基因本能是用相对固定的有序结构实现的，只要复制这个种子结构给下一代，下一代在此结构的框架上演化就可以了
没看懂你说的化学物质对应特殊刺激是什么意思
我觉得你说的好象和我的问题不是一回事。不同脑区神经细胞兴奋时，突触释放给受体神经细胞的化学物也许会不同。但是都会有相同的作用，兴奋或抑制。你说的和这个没关系
还有就是同一种递质对不同脑区神经细胞的作用也会有不同，对这区域是兴奋对别的也许是抑制或不起作用
目前想到的可能性有两个，一是信息压缩与多样性，一个脉冲传递不同信息，另一个是鲁棒性，稳定遗传变异和提高对外来神经毒素入侵的抗性耐性
谁标记？什么方法标记？
别搞情感模拟什么的辅助内容，别人已经都做到了，也够好了。人的智慧在于，认知、想象、选择。第一层面，是认知，首要解决的就是，比如人认为物体是苹果，可以通过看、闻、摸、吃等方式实现，苹果肉、苹果泥等都会判定是苹果，但人工智能的话就不行了，你预编辑是没用的。
你只要开发出认知系统，就够使得科技迈进一大步，大到你无法想象！！！
 你这些有好多是不需要自己去做的，那样会增加工作量也会浪费自己时间，如果做偏语义方面的认知，可以学一下自然语言处理吧，这个是根基，处理完才能往下走。
目前高三 还是先好好学习吧，有很多情况是 硬件好，效果就好，所以说你先努力上好学校，然后再搞这些东东~~
[阴险]年薪10W太低了吧，能看paper，会github，编程能力不错的又懂点BP和ML，20W给我来一车
你以为能看paper,会github，编程能力又不错的人很缺？你以为能看paper又懂BP和ML的人刚毕业薪水能超6K? 我羡慕你的天真
 别的不说吧，有说看paper，多少毕业生，可以拿出一篇ML的顶级会议文章。准备30分钟，能够直接口头report的，能英文交流的有几个？
看paper的难度，不是那么大，入行之后看paper的人真的不少，会github的人也不少，英文交流能力毕业生确实不怎么样，但是混几年英语水平不差的也有好多，别以为这些能力真的那么珍稀。
关键是，对应的岗位少，真的没几个公司要懂深度学习的人，需要深度学习的公司，更看重C++和hadoop spark的能力，深度学习算法也就调参数，BP原理真的不是只有少数人懂。
反正我们贴了一年的广告，招PhD和post-doc。P个人都没有来过。怎么也比企业轻松太多了吧（早上十点多来下午四五点走，不来不用请假，节假日寒暑假），15W-20W/yr
面试过的PhD，真的没几个行的；实在是离期望差很多
到各类主流DL库的github和gitter上面找人吧，我看头像是中国人的蛮多的。
[委屈]我觉得他们不会为了这么点钱来的...
三年后，估计符合要求的人会多如牛毛，4年前数据分析师稀缺成什么样了，今天一招一大堆。
phd要求太高了
看文献至少要66666啊，不是PhD还是差点
确实，谢谢忠告
其实刚才想问的是pars数组里20种abcd是指不同种类的神经元吗，我知道它们是数学模拟，没直接性的生理意义。
借此楼问个基础的东西，大脑不同功能区神经元的这些参数不一样吗？相同功能区是一样的吗？
哦，了解，多谢解答
说不定某种AI算法能提高胜率呢？人脑未必能够实现真正随机，或许会有某种规律可循
我开始怀疑这是炒作。学坏了也是因为教的东西不好。学的很快。。。。
教的东西不好是外因，没有甄别能力是内因。另外学得快是很正常的，它一分钟“听到”的话可能比你一辈子都多
我对它学到非常糟糕敏感的东西（炒作条件）的概率表示怀疑
概率不小，比如这种言论可能很火
不可能比时事新闻更火吧。比如阿尔法狗
可能那种也学了，但是觉得发那个不够个性吧
针对明星或者其它的公司或者公众人物比如政治人物容易引官司。而希特勒啥的找不到原告。最容易炒作
这种很明显不是炒作，这种应该算事故，毕竟是负面新闻
凤姐也一直是负面新闻。但有经济利益。现在这年头不炒作是混不下去的
你读了报道之后对这货能得到技术烂的评价么。
能啊，我立马觉得微软被谷歌甩了八条街
首先谷歌没有同类产品没法直接比较。其次，微软既然有团队在做这个东西，总得出来冒个泡利益最大化一下吧。如果你是微软团队你咋做？
我觉得出了这么大的乌龙就等着被炒吧
你觉得真有弱智团队会真的不审核AI的言论而让它直接想干嘛干嘛？
以前我以为没有，现在知道我以前错了
好吧。如果不是这个负面报道你知道有这个东西么。
我知道有微软
对
你确定媒体报道能比比尔盖茨发一个twitter更管用吗
当然。如果比尔盖茨天天发twitter宣传啥office win10 vs 还有各种乱七八糟的东西。我相信他粉就快掉光了
而且现在技术不够成熟，还没到力推阶段。现在也就是时不时冒个泡，保持下曝光率关注度。积累阶段
要说不成熟的话小冰早就几百万关注了，当然要说真成熟可能一万年也达不到
机器视觉瓶颈在硬件。是时候开始研究自然语言了[笑眼]
另外广义的 one-shot learning 还会牵涉到各种泛化及推理的机制，也可以挺复杂的。这是个很好的研究课题。
稀疏自编码，无监督，聚类，降维什么的都和数据压缩差不多，就是用最少的编码长度记忆/描述输入分布，本质上都可看做是熵编码的连续版本；低层的也可以认为是祖母细胞，只不过它们描述的是低层的类，而IT类的高层也可以认为是分布式的，比如场景是由IT类的稀疏分布式激活编码的，场景类更像祖母细胞
祖母细胞是指local编码，极度稀疏的一种情形。
单个卷积核难道不是local编码，而得到的map难道不是distributed编码吗，而这个过程是不断重复堆叠的，每一层完全是类似的，所以你找不出中间的哪层可以说是绝对的local/distributed
其实我觉得使用卷积核共享+池化的思想逐层做autoencoder也可以实现足够泛化能力的GM。话说当年ng做的google cat那个是怎么做的？有监督还是无监督？
要做GM最基本的一个问题就是记忆的精度如何自适应可调，在ART里是警戒度，在autoencoder里则是还原误差的权重，并不是所有数据都需要等精度地记忆，有些样本可以只记忆分类面附近的。记忆精度和泛化能力一定程度上是冲突的，提供记忆精度会使得系统过于保守，反之过渡泛化。
似乎人类在婴儿阶段倾向于过渡泛化，有助于记忆重要的东西（特征），将学到的少数知识举一反三，广泛试探这些预测的正确性，而随着年龄增大倾向于过于保守。
这层总结的可以，哈哈
 google cat 基本上是用个 deep autoencoder 进行大型的无监督训练。Deep autoencoder 能逐层提特征，如果够深且样本里有大量猫脸的话自然就会在顶层产生出可以检测猫脸的巨特征。
我现在不认为discriminative model是个问题了，只要把softmax换成center loss就好
GAN(Generative Adversarial Network)，生成对抗网络.同样没有自适应动态调整泛化程度的参数，甚至原文里控制泛化程度的参数都没有：V(G,D)的两项贡献没有加权因子。
一个拉近余弦距离一个拉近欧式距离，余弦距离加了偏置项后不比欧式距离差。softmax每个类也有一个(余弦的)中心啊，例子中把用余弦距离(softmax)归类的点画到2维欧式空间中来说余弦距离的不好，这不太合适吧...softmax实际上应该画在3D空间中好吗...w有两个参数，b还有一个参数呢
一个是(w1,w2,b)与(x1,x2,1)的内积，一个相当于是(w1,w2)与(x1,x2)的距离
把softmax训练的(x1,x2,1)归一化成(x1,x2)/sqrt(x1^2+x2^2+1)不就可以直接得到center loss的结果了吗，当然由于训练过程不一样肯定会有些差异，但基本上是差不多的事。
现在有一种网络变种能解决 同一物体不同形态的问题，就是两个网络共享权值，输出端对 同一物体不同形态的输出做二范数处理并反向传播，可以使网络对同一物体的不同形态产生差距不大的网络映射。。。lz看看能解决问题2不？
情况1，比较复杂，人都不一定能很好的分出。
哈哈，看到你楼下的GAN就懂了。不过每次提到这个网络都有种莫名其妙的喜感[哈哈]
情况1需要创建新的表征结点来分离本来属于同一类的事物，而又不能随便创建新的结点，这样容易受噪声影响将同一类划分太细，实际上按照ART，人类是每次犯错就提高一次该语境下的警戒度，足够警戒时，才创建新的表征结点来分裂一个类，以实现最小记忆最大泛化。
BP微调只会把该类的标签平均掉
问题2直接用BP就可以解决，只要数据扩增做得足够充分
因为理论上数据量足够多时，视角、光照、姿态都是流形上的一个自由度而已，足够的数据使得同一个类的流形不会断掉，而不同类的流形只有少数区域可能会相交
没错 就是这样[真棒]
上面其实说了两种情况2容易被解决的原因，1.BP有能力将多个小类合成一个大类 2.数据量足够多时，无监督学习一般可以避免情况2的出现，更容易出现情况1
也许情况1可以通过层次聚类+BP解决
 简单的 fine tune 效果有限。农产专家看葡萄提子的时候可以看到很多一般人看不到的特征，所以原则上我们也可以让系统做深度的fine tune, 进一步根据需要学习更精细的特征。因为这是【根据需要】做的，所以感觉像是一种有监督提特征的机制。
问题是基于BP的fine tune永远不会将原来的一个表征分裂成两个，只会将葡萄提子按50%的概率输出，因为它已经陷入局部解了。如果使用跳出局部解的手段，则可能会随机毁坏无监督聚好的类。总之要和无监督尽量兼容的有监督fine tune简单BP是不够有效的
 同意。这个显然是需要个新的机制而不是简单做基于BP的fine tune。
 center loss 是有点意思，可以部分解决传统DM过度泛化的问题。不过这方法並不适用于 disjoint set 的问题，即是如果一个类别在特征空间形成超过一个cluster的时候（如某水果可能是红【或】黄色，无其他色）这方法就无效了。
梯度下降会强迫最后一层在相应度量准则（内积或欧式距离）下聚为一类的，不然softmax会因为非线性能力不够而有很大的loss，分类失败（这说明根本没有训练好）。即只要loss足够小了，那么一定意味着最后一层的激活就在相应度量准则下是聚在一起的。
这也是为什么softmax loss会聚在扇形区域而centor loss会聚圆周附近的中心点上（相当于扇形归一化了），并没有一个类分成很多分支。
有理。
楼主，我找到了适合聚类的层。以ImageNet的ILSVRC12 的八层模型为例，取conv5层可以很好地聚类，前面几层都不行。具体分析我会在后面贴出。
好的。基于哈希编码的图片检索一般是用哪层的特征？
只知道粗略步骤，不知道细节。
没记错conv5应该是卷积最后一层，神经网络提取的特征本来定义就是隐层输出结果，所以当然是第5层后的输出。而后面3层其实就是感知机，用来把卷积输出拉成向量，进行传统操作。至于为什么大部分网络最后的FCs都是三层，仅仅是因为三层MLP可以以任意精度逼近任意连续函数，层数没必要想那么复杂[哈哈]
还有imagenet本身是一个结构化数据库而已，可能我理解有误，也可能是层主理解有误。看了另一个帖子，层主应该是在研究caffe，顺便在这回答下LRN的作用吧，CAffe使用了ReLU激励，Relu的好处咱就不提了。但要注意的是Relu的映射值域是无边界的，sigmod和tanh都有界，也就因此要加个规则化，所以选了LRN
有些事仅此而已，没必要想太复杂。理解模型整体时应使用我们与生俱来的直观感受，而理解底层细节则应从纯数学角度来看。[哈哈]，希望楼主多发帖交流啦
顺便说下层主的这个网络可能是AlexNet吧。。。卷积层5层 三层conv加二层Pooling？输入小于900，第一层FC 4096？后接3层FCs的吗？是的话就是Alex或其改版了。。
我是在学习caffe，这个网络就是那个典型的八层网络。我现在学的不深，后来的几十几百层的操作工作量太大，暂时没去看。感谢你的提示，我还需要做一些编码实验深入学习。
没事[哈哈]，只是这个贴吧正紧发帖的不多了，多交流~
你在说这句话的时候，就包含了无数的猜想，而且你还在期待反馈，这就是智能形式
作为一个机械工程师，我想说我的产品都是认真做过设计的，从来不瞎猜
只是从经验中寻找最优解，把一个领域的知识运用到另一个领域，解决了问题，这应该就是创造吧，目的和目标才是最主要的吧，存在必定有理由
至于用什么样的思维方式去思考，或者思考的过程，涉及到逻辑，无非就是条件判断，模仿学习，还是以人的思维方式，经验产生经验
猜想是智能最重要的部分，很多人都没有意识到这点，做无谓的数学推导，那些计算产生不了任何智能，那都是建立在已有的规则之下的
而猜想最重要的课题不是在已有的经验中寻找现成的解，而是尝试可能相关的解，然后通过反馈来强化猜想正确率
这里要再次强调的一点！猜想不是在已有的经验库中去找一个现成的解，如果你这样去设计程序，是永远不会产生智能的！猜想真正的做法其实很简单也很难，就像但是目前我还没有找到，思路是有的——寻找一些可能相关的解，再通过实践反馈强化猜想的正确率
联想
抽象的前提是通意象，你要是能让机器理解什么是意象，人工智能便真正的出现了
纯数学推导肯定有问题，因为人们只有在计算钱财时才计算出具体的数值，其他时候对任何事物有一个概念罢了。 对概念的理解，有助于深化认识，归纳已知和未知，找到智能向前发展的边界。 找到已知和未知的转化方法，通过试验、正向思考和反向思考，可以适当地探索未知，我觉得这是智能的初级形态
这些知识的存储还是概念“重物砸死人”，因此说，对概念的理解、表达和尝试是可以做的，也是很快可以成功的，这个思路可以超越deepmind
超越人类，当前还比较困难。因为人类是多重传感器，多个方向思考问题。 机器人首先也需要专业化、联合化，这是获取新的经验的基础，否则没有多样化就没有创新，这一点与人类似。机器人派生的任务交付给其他机器人、管理机器人也是应该的，但机器人管理可能会更高效吧，没有私心杂念。
人类的记忆也比较复杂，类比、抽象、模仿等。单说经验库，这个容易实现，但如何存储调用、更新、优化、树立权威而又解释反常，改变规则时如何相应修改，是太复杂了。
是数学算法之上，代码太简单了
还有么
会做吗你
欢迎提意见与需求。
你大致说一下你怎么做的呗
只要我的语料库里相关语义的句子比较多就认为是通顺的。
一是词语搭配，二是语义搭配。
其实更严重的问题是色弱就缺乏性趣,甚至阻碍娶老婆.
额 我那个是数字图像处理 不是单纯的图像处理
老哥 是不是没影响呀
谢谢大佬打这么多字回答。不过我的方向是深度学习，学习的是神经网络 这个会有影响吗
谢谢谢谢 但是我想学深度学习 涉及这个吗
影响不大，你看得到RGB数字，还能分别显示不同通道区分颜色，顺便做小白鼠，说不定你与他人的差异迫使你从其它角度发现突破口呢。
神经网咯，咱不了解。俺就是想着做机器人才鼓捣图像识别。
🙏谢谢
嗯哪 
不同的分支而已 深度学习影响应该不大。我下周三才开始学深度学习。 下周二机器学习结束。 后面有神经网络和 nlp图像识别。 最后看个人 哪个学的好就去面试哪一种的。
你是读研的嘛 大佬
我是大专   
这个社会看技术 加油 
nlp不是自然语言识别么。。。怎么变成了图像识别
说的很明白
额额。 我蒙了哈   
我自然语言布吉岛艾   不好意思哈！其实图像识别也没学到呢
在编写图像识别算法时，色偏也会误导各种参数。调用开源算法没有影响。
五音不全的人最好不要走歌唱之路，有恐高症的人也不选择高空作业，对色彩不敏锐的人尽量远离色彩图像相关行业。人得扬长避短。机器人的关键技术就是图像识别，不要指望开源图像算法就能解决问题，自己动手编写算法特别需要敏锐的色彩感。
根据语义搭配与词语搭配选出一个较优组合。
前后情节要符合逻辑还很难。所以现在我要统计各种事件的作用与后果。
哈哈，我也在搞这个相关的。不过我的思路和你不一样哦。。。。。
如果方便的话，可以透露一二，欢迎探讨。
现在我解决了很大一部分了，你有商业需求的话，也可以给你提供服务。
使用的语料还是比较少，可供选择余地少的时候就比较生硬。
差异肯定是有的。
语料是很多，处理起来太费时间，所以先拿一个处理了一部分的结果测试。
我最近的发现 经典诗词是最优质的人工标注：1内容聚集于常识领域：自然景物，生活流程，最常见的思维2经过千年筛选仍被广泛接受的文字，引用程度高，可直接加上100倍权值。 3原文-白话疑问已经是双重标注，包含了词汇的简写对应 4体现了中文-自然语言运用的原始状态：最自由的句式组合。
另一个常识性知识图谱是知网的概念分类库，今年三月董老去世前公布了增强版的词林概念库
词林概念库搜索到概念之间的关联，如果充分发挥，推理能力超过英文的推理引擎
诗词离现代口语太远，既然目的是服务于现代口语，那还是要以现代口语为主。
我一个人做相当于一个百度公司的工作，可见我的体系的自动化程度了。
我看书是一目十行，做IT前看了无数小说，做IT后就基本不看小说了，我已经把时间用到极致。没有比做人工智能更有意思的工作了。
“20篇”的回复怎么删掉了？20篇是远远不够的，你说够我说不够是因为我们基本观点有差异。你的出发点是跟普通人比，问它任何一句诗答不出来也没关系。我的出发点是电脑综合考量已经超过人类智能，我是跟电脑比，要求它掌握人类大部分知识。而且使用海量语料可以减轻开发者工作量。
是整个人类的大部分知识，而不是单个人类的。
听语音与看视频是我完全不能接受的，信息接收效率太低了。
我宁愿电脑多读一万本书，也不愿多占用我挑一本书的时间。
所以我二十多年没有看电视了，完全是高速奔跑，以后可能要慢慢放慢节奏了。
20篇当然不够，但作为核心完全够了，后边的知识可以20篇的内容生长出来。
然而你为AI写了多少代码呢？ 核心能力不在多，别说一万本书，一本书足够让AI迷失方向。 比如说对于知网概念库，最头疼的就是它为一个词解释了过多的义项，得花功夫考察那个是原始含义。
AI只是一部分，我基本上以个人之力重建了IT大厦，差不多有一千万行C++了，当然有很多是一个项目多个版本重复计算的。
虽然有重复计算的，但是基本上都是自己写的代码，除了一点VC自动产生的框架。我基本不看别人的代码，那样根本没有我自己写快，一般都是一挥而就几千行，基本不需要调试的，而且基本没有推倒重来的情况。
由于一般都运行在自己的平台上，所以我开发的软件基本上是永不过时的，二十年前的代码依然可重用
对代码是真爱啊，真喜欢自己写。不卖出去钱再请别人写么，发达了也好提携我们这些苦苦劳作的。 我没正经学计算机，所以一天三百行就是极限了，不过目前为止还没觉得考虑过的流程无法实现的。真无法想象千万行的概念（千万行早该无所不能了，不全是指AI项目吧）
及时算上注释200行一个函数，这五万个函数怎么管理？光做个目录又是上百万字
不就是嫌人家写的不满意才自己写的吗？有钱可不一定买得到好代码。这不是一个项目的，涵盖了IT史上多数重要工作，拥有了全线的自主知识产权。数以万计的科学家用几十年建立了IT科学大厦，我以个人之力就可以重建了。
这个倒是。让别人写出来绝对比自个写费劲得多。 不过光自己干终究不行......赶紧换成钱搞个基金会嘛
欢迎贴一些实例，提一些难题。
我这个方法就是适用于生成式翻译的。不过你找到的句子应该是通顺的，否则就是语料有问题。
谢谢！如果说通顺的话语法上都算的上通顺，就是很多句子太生硬，用户体验肯定不好，所以想筛出最合适的，多筛掉一些无所谓
我现在的统计数据都是放在机械硬盘上的，所以速度还上不去。而且现在又在忙搜索引擎的事，稍晚一点我可以帮你筛选一下。
民科你好，民科再见
那个是国外的较专业的平台，这个吧是国内能找到的主要以交流为主的平台，由于人比较多，主题又是人工智能这样的热点，来的人就更多些，这样容易起到一定的科普、交流的作用。别的智能方面及相关的例如python交流平台人太少，没人气。有个python吧，看起来有些人气天天更新，假的，前面几十页只有广告。
你能想象吗？发个言之后，转眼找不到了，得翻个几分钟，终于在广告海中找到，这样，陌生人可能上次当，知道的都不会再去。
以后，要攻击敌人的某个论坛，就用这方法，多发点广告多注册点号。
Stack Overflow什么的哪有国内的贴吧有意思  ，ICU完轻松一刻。
你没发现这贴吧就楼上还有别的几个人回复最多么，仔细看多得反常。
水就完事，不予置评，害怕网络喷子。
这是开普勒研究与总结的天体运动规律，牛顿在此基础上瞎想出引力的原因跟质量有关系，当然啦，是不是就不说了，反正数学上满足开普勒的科学观察数据，所谓的联想，也是要有概念的，没有概念的联想，那是空想。
你好，最近学校有个项目跟这个类似，我0基础，想参考一下你的代码可以吗[泪]
复杂的统计得到的，代码就不公开了。
肯定要获取以前的走势啊
那就不是“提高概率”了，而是“发现其中的概率”。
人工智能并不能提高概率，因为概率只跟所获取的信息有关。人工智能只能去拟合这个概率
执迷不悟，只有破产的份。我是庄家我想怎么开就怎么开。
还是你有慧根 
太复杂，我这初中毕业的确实很难搞懂，只懂一些简单的凯利，大小数，
真实世界中客观都不一定存在，更何况是人为世界的规则。这些高度抽象的技术，对现象的长期解释力低于 1%
一直搞下去就是亏律 
模糊算法 自己看论文
看来都对钱没兴趣啊
是有解还是无解？
词语相关性分析做了没有哦？
没有重点去做。
正比反比不就数学吗?
不要本末倒置好吗？正比反比，和万有引力的本质不是正比反比
万有引力的发现不是靠你知道正比反比就能发现的
1、自我学习是猜想模型的初级阶段，它是通过外部输入新的学习素材来补充自己的经验库，再进行验证，反馈，强化已有经验。这种形式算是很接近猜想模型的一种实现。
2、它仅仅是初级阶段，不是最终形式。因为通过刚才的描述可以发现 自我学习的过程目前依靠外部强制性输入 这个行为其中没有包含自发的 由机器自身所产生的猜想 也就是近似解 那么从封闭系统的视角去考虑 它永远都处在已有经验的封闭系统之中 无法取得创造成果
如果这样一个系统运行下去，它的最终归宿还是一台专家系统而已，并非智能机器。
对，楼主这是把意识和信息处理当作是一种东西。自己还不知道，一会说意识的能力，一会说信息处理，自己认识的不深刻，说乱了也带乱别人。
话都让你说了，你自己的原话是如果没有假设反比正比，就不会得出万有引力，一扯数学，又说不是靠正比反比能发现的，也不怕自己打自己嘴巴，玩的太溜，总之杠就是你对完事了。
正比反比除了牛顿，地球上大把人懂
但是他们发现了万有引力吗？所以创造性的成果是靠数学才能发现？
很好，这才是展现人类智能的关键一步
以机器的算力，可以无时无刻在自己内部做猜想进行验证，而且速度比人类快的多，人往往做一次头脑风暴都会疲劳，而机器并不会，所以机器的智能潜力应该远远高于人类
逻辑猜想有可能通过逻辑运算解决，但是事实猜想需要搜集已知证据，有可能还需要通过实践实验增加新证据。我的方法是，由AI发布所需要的新证据，让人类接取悬赏任务，完成实践后向AI提交数据或者自然语言报告。
这可能是未来人类新的工作！
非常棒的想法
瞎想和联想是不同的，万丈高楼平地起，有没有基石很重要，60亿人去用正比反比，也能涌现出一个人，从正比反比的基础上琢磨出一套东西来，那是必然的，不管叫啥名字，但是同样不管你咋想，咋牛逼，去搞炼金术这种没有基础的东西，一样给你搞砸。
你的理论非常不错
有的啊，看我的奥数数列等等功能。但是如果真的是随机数的话，就是没有规律，没法自动学习的。
大佬可以合作交流下吗
忠言逆耳，良药苦口，多谢提醒！不过我的作风自认还是很严谨的，否则禁不住神经网络派的攻击。有些做派只是与时俱进而已，本来就是一个人在战斗，自己不给自己发声，那就只有在无声中沉沦了。
敞开大门欢迎。
留个东西啊大佬
你看谷歌都已经什么地位了，还经常要亲自下场，用各种方式发软文带节奏，我可不相信它在国内没有相关经费投入。革命不是请客吃饭，温良恭俭让是不行的。做起事来不用客气，高歌猛进有何不可？
我是说，谷歌都那个地位了，还在使用一切手段谋取利益（依然非常进取的态度）。你一个个人还要束手束脚，哪里可能干倒它？只有不断涌现出新强者干倒旧强者，这世界才能飞速地进步。
任何事都不可能一步登天的。努尔哈赤十三副遗甲起兵的时候，我相信只有他自己有取得天下的信心。他自己有信心并且付诸行动了，你一个旁观者连他的信心与路线图都看不出，哪里有能力依据他起步时候的战斗胜果微不足道来否定他？
我宣传的那些方面做得是比它好啊，你可以叫它改进一下再来跟我比试，看看谁胜谁负？
不宣传就不会有以后了。
它们不择手段地宣传，还不准我宣传？我绑住手脚跟它们打吗？
有漏洞的地方你可以质疑我，但是在你的质疑完胜之前我完全可以这样宣传，这东西毕竟是帮助了一些人，也没有害人。同样的，你也没有能够让谷歌、open ai停止宣传啊。
而且很多人都会觉得说的是一个愿景方向、苗头趋势，愿景方向都不说得鼓舞人心，人生还有盼头吗？
希望你能理解我们各有各的风格。
我还是不愿自缚手脚跟它们打。
管道是逻辑结构，物理结构可以为数据总线、系统集成接口等[呵呵]
有很多学者不断询问计划型雷波是什么？由于语言过于精简，所以不理解正常。在这里解释一下，魔方的起点为核心散发无数进展路线，整体如球状闪电发散波。计划型如同模式，用于未来各种粒度上的复用 重用。同匹配不同，侧重效仿复用，无数发展的可能性，无数选择的时间线的AI智能结构
进度路线图由无数个进度节点组成 节点下是针对节点的思路算法 由外界与内部条件触发选择不同思路直到不同算法 不同算法整合不同专业模块流程的智能整合过程 由反馈纠正性调整 幅度有条件微调 中层重构 顶层借鉴性大调 [礼物]
魔方模式(大模式)为战略发展魔方，侧重创造性发展即战略发展，为了更好的战略发展，在魔方成熟度基础上从战略主线上设下无数布局，具有极强的创造性主动性，但其架设的格局极大所以对于底层不太直接有用，故称为大魔方。每个节点都是发展阶段，在每个节点中都有无数的局，布局是为了争夺阶段发展条件
度娘你删我多少页啦 女人要学会矜持与柔情 https://www.bilibili.com/video/av43429654/ 极端另一面 剑火[乖]
时间线上当使用魔方后而改变了时间线走向 从宏观上看就是线上交织着巨大圆球 当此时间线上又使用了多次魔方 即在线上排列了许多圆球 圆球交织着无数的时间线 这就是未来宇宙时间线 为什么说玄无宇宙就是神经网络黑匣 就是这个道理[太阳]
不是卷积 我真的怀疑你们的理解力 到现在为止你们还不知道魔方属于符号智能 虽然它可以改造成混合智能 你们都认真看了吗 理解了吗[睡觉]
从这里也可以推断出其根本没看AI分层 魔方属于AI顶层以符号智能为核心 所谓卷积等神经网络等都属于最底层的专业感性智能 说明AI分层也没看懂 哎！！
我不需要你们宣传 而是让你们知道未来AI的模样 同时也要提醒你 不要说写个小小程序就算拉上整个神经网络 如果不按上面的做 所谓AI就是你们又创造的近亲结婚式的电子LJ 你以为我需要你们给我宣传 哎！！我不想刺激你们不要误会！
为什么会觉得写个程序就能解决AI问题呢 请问你一生写了多少程序 解决AI问题了吗 我终于明白为什么此地自然科学发展如此之慢 看来是有原因的 这是社会环境间接造成的
所以希望你能为AI添砖加瓦 未来靠你了
我总结一下虽然你犯了不少致命错误 而我认为你犯的最大错误就是误认为AI就是程序！ 道不同不相为谋我不想和你讨论什么 我解决的是AI问题但不是简单的AI而是强AI 甚至超级强AI 你脑中一直要和我灌输底层的功能模块AI 也许功能模块AI在要求不高情况下 写个程序能凑合 但毕竟谈这些无意义

有人问涂鸦公式想表达什么？ 意思很简单神经网络的权重公式可以转化成非线性函数 即非线性统计分类函数 虽然我们不知道它挖掘出什么公式 但神经网络明白权重方程 划分非线性比例分类 权重公式是为合理分类分配多少比例最精确服务的 从数学角度看 神经网络可以解决一元、多元一次、多元多次方程式
所谓的神经网络的权重公式最终形态 由大量学习训练决定的 所以同样都是同类神经网络所挖掘的权重公式却各不相同 但是权重公式最终可转化成所有数学方程 现今的深度学习等新型神经网络 都能解决极其复杂的非线性分类问题 智能计算需要神经网络！！
但只要在神经网络基础上稍加改进一下结构框架 就能在琴弦上附加前所未有的气势 这个气势就是智能的意境 https://www.bilibili.com/video/BV1PK411L7h5/?spm_id_from=333.788.videocard.4
设计强AI时必须严格考虑3W问题，扣心自问自己做到了吗，为什么没做到，问题出在哪里。设计思路要科学清晰！所谓3W就是what why how，这是设计非**能的最基本原则！！
我可以明确的告诉你 大脑在某些机能里确实没有做任何运算 包括我说的图像识别 大脑的运作机理根本就不是运算 和你说的是逻辑运算更是一点关系都没有
神经网络通过权重公式来实现线性与非线性回归算法 统计大数据的逐步回归来无限接近解决问题的正确答案 所以AI底层框架的智能计算与植物感知需要神经网络处理 而ACT-R或图神经网络、搜索式知识图谱都不是真正理解式认知 想用极简架构来模拟认知 较适合非常原始的条件反射、潜规则等浅层认知 但强AI不够
紧密绑定的(理解在一定程度上也包含了与价值意义相关信息的把握！) 这句话我就不加了，因为常识性描述就不啰嗦了
感性理解层 即感性+理解层 精炼语言表达不多余字
求解每种状态下的最佳动作，主要是有个贝尔曼方程，这方程用神经网络通过状态——动作——回报——新状态的大量数据去拟合，能直接或间接的获取状态——最佳累积回报的即时策略。感兴趣的可以看看强化学习方面的书，这类书我都钻过好几本了，感觉写得都有很多错误，说明这方面东西还不太成熟待改进。
不用神经网络，用表格去表达贝尔曼方程也是可以的，能直接获取状态——最佳累积回报的即时动作（实际上这也是策略），但表格可能过于庞大，还是神经网络代替表格实现这种映射方便、现实。
lol这样的游戏，如果机器先学习一些先天基础，就相当于层次化目标学习，再利用这些基础去打，应当比围棋更容易，但当初发展恰好没先走层次化强化学习这条路，现实中围棋有更大名声且算法考虑到位且不太适于层次化目标去实现，反而显得机器横推较适合，所以先攻克了这个。
围棋场景独立性不如lol，不好层次化目标，前后关联交叉太强，整个一盘棋作为整体考虑才行，不能分场景的方式缩小空间，只能在树的深度上减小空间，但减小树深度实际是一种折衷。lol分层则将部分运算限制在场景中，当然，最后有综合分层目标的再强化，如果这样做，就相当于人类有一些基础，例如能判别
敌人的移动，能判别己方的移动，……，这些是基础，有此基础后的训练，就相对简单，比什么的不会的婴儿从零开始要强，当然，婴儿也有一些先天的，比精子还没遇到乱强。
围棋对层次化的先天基础利用不大上，也不强调机器运动反应的优势，机器达到普通人练习时长100小时水平的学习难度其实很高，lol机器运动反应包括视觉、动作较人类视觉注意力、敏捷性都有优势，要达到普通人练习时长100小时水平，其实容易得多。
之所以现实中lol机器难搞，是因为层次化的先天基础这上面投入不够。
如果先天基础有了的前提下，机器只学习后面的再强化，应当比围棋容易。当然，你要说先天基础一块算进去，那肯定lol先天+后天的总工作量就更多了，因为做了些多余的工作，那些先天基础也考虑到了其他通用任务共用，从零开始也算进总工作量这就有点多余。
这么夸张吗？
没有那么夸张吧
大佬牛b
如果说分布式训练呢？ 搞成半监督或者监督模式 ， 开一千个游戏窗口来训练 每天的训练量=1000x40左右 每天4万次训练 一个月100W+的训练量。 或者在提升x倍 一个月也能见成效吧
大佬果然**
第450次 d_loss,acc: [0.11358509 1. ] g_loss: 0.11010793596506119 如图所示 这里显示 判别器的准确率是1
实际测试 生成图测试全错 真图测试也只有0.73的正确率 为什么？
我训练的时候判别器收敛的特别快 准确率很快就到1了。 我是哪里写错了吗？
D_loss 第一列是判别器损失，第二列 是 判别器准确率取值范围是0-1 【判别器损失，准确率】
疑惑的是前面显示判别器准确率=1，后面使用evaluate 函数评估模型的时候准确率却只有0.73和0。 训练和评估用的数据都一样的。 Keras写的
其实这个是抄的一个博客的代码，不然等会我把链接发一下
我有一本书，叫21个项目玩转深度学习，其中第8章就有mnist的生成对抗网络内容，看了下，与你的在起变量名、类名类成员名上都差不多，估计是一样的，但书上只简介了下，书上没写代码，代码在的每8章中，然后还要额外下载mnist多个数据文件。我在下载mnist解包时报错。
如果慢慢看它的代码，能搞清楚mnist的代替方法，因为很多mnist的来源，甚至tf及sklear都自带mnist数据，但它用了多个类和方法的繁杂框架，如果不细看慢慢看就不好改，我不想去看，它的main文件就几十行，用了可变参数的设计，所以繁杂，model用了几百行，当然，也是为了进行各种超参数执行时可变。
反正我一看有几百行，懒得去看，性价比太低了。
后面那个日本动画人脸的gan我是弄过的，训练出来也还行。
以前mnist数据集yanlecun那个下载过，是有这个数据集全部4个文件的，后来没怎么用了，就偶尔用用tf和sklearn里的手写数据集，刚才居然从另一台机器里找出来了
正在运行呢，初始d损失1.9,g损失0.85，一会之后，前者1.4,后者0.6几
我现在是在笔记本的cpu运行的tensorflow，所以很慢，都10分钟了才运行完1轮多，总共25轮呢
g_loss的数值应当与d_loss加数中后半部分的值相同，只不过一个在判别训练中使劲增加，一个在生成训练中使劲减少，一个改判别器的参数，一个改生成器的参数。
都要6轮了，能看出生成质量越来越好，但d_loss1.39左右基本没变最多微降，g_loss也相应微降到0.67多点，d_loss由两部分和组成，后半部分应在数值上与g_loss基本一致，应当是生成器反映在判别器输出后的损失，只是生成器训练时与判别器训练时的增减目标相反，但每次微小迭代改变不大，值应相近。
并且，我通过看楼主的图与我的图的差异发现一个问题，我的图是灰度，楼主是彩色，这种情况，楼主最好检查下，图片像素点应除以255，别去中值再除以127.5，这样的像素不是0——1间的浮点数，图像显示时会错误当成其它模式。
楼主是先除127.5映射到0——2，再减1，这样最终映射到-1——1间了，显示的图片就会模式错乱，显示程序不会将数据还原成灰度的。
如果楼主坚持这样归一化，那记得显示数字的时候要作相应处理，以免显示错乱后以为训练没对。
训练完了后损失只再降了零点几，图像质量更好些。其实十几分钟后质量就很好了，毕竟是低分辨率。
[哈哈]谢谢大佬，我终于找到了错误点！ 我是训练判别器时，真图片和假图片分开训练的。 先训练的真图片，更新梯度后，后训练的假图片，再更新梯度。 再训练生成器。 这样就会导致判别器训练不成功，原因其实我也没明白。
 在我修改成假图和真图都训练完后，一块更新判别器的梯度。 就全部正常了
@胡梦柯5:总之谢谢大佬帮忙！
训练判别器时真图和生成图的损失之和都要起作用，当然最好一批送入，但如果分开训练，其实也能行，你可能是真图送了判别器，生成图后来没另外训练判别器。
现在这段代码看起来比前面那段清晰多了。
看到都轮流送进去了的，那可能前后代码的根本差异可能在于d_loss的获取方式不同，导致优化时结果不同，例如np.add可以换成其它试试。
其实可以分开送就分开优化，分开送了一起相加再优化就不对了。你后来做的一起送，实质也是在同一批内分开送分开优化。
对判别器来说，真的尽量判别真，假的尽量判别假，以回归为例，真假损失相加后正负的差异与差的平方的相加是有符号影响的，误差的平方和，而非误差直接相加。
估计差异是在train_on_batch里造成。
感谢大佬，我的问题也解决了
遗传的那部分，实现上可直接指定，可通过映射函数表达。具体可以通过数据样本进行有监督学习。
学的时候，学出来后，都可以在一定程度上加入噪声，然后与人类群体交互，在自身的判断力中有条件的受人类影响，不要求固定美感。
美感的应用就很多了，短视的应用是建筑、绘画、作曲、烹饪、……、等需要美感的设计与制作。
你与楼主先出现的问题差不多，楼主后来纠正了，他是改成同一批训练真图及生成图。
修改内容在八楼。
虽然同一批训练既有真图也有生成图，但真图和生成图的标签区分开来了的，所以训练时loss根据标签得到不同的增减。
你好，我想问下，对于DCGAN模型，怎么设置最后的迭代终止条件啊，还有一个就是我的判别器的损失函数，训练２０００次左右的时候，损失函数在１．１左右，然后用测试集去测试判别器，准确率是１，但是再接着之后会出现损失函数降低到０.５左右，但是准确率确下降了，生成器的损失函数也增加了，
请问这是正常的么
可是我的代码和数据集复制在其他人电脑上正常 
没呢，现在只搞DEtect文件了，训练放服务器
同样的代码放别的机器上没问题
你如果理解了代码，就可以在中间加入测试，以局部化缩小问题范围。
你可以尝试输出部分中间可作辅助判断的数据。要做搬运工也要做有素质有脑壳的搬运工。
你还可以试下在有问题环境中简单些的程序出现类似问题没有，有的是办法推断问题所在。
可能性很多的，包括版本、环境冲突等，中间如果需要诸多工具包的支持，随便哪个有问题都可能造成错误，甚至环境路径冲突都有可能造成有的文件找错了的错误。有些问题，只有逐步逐块执行才好定位程序哪里表现开始错，再想法寻找问题根源，实在找不到，问题又经常发生，重装环境是最省事能解决的方法。
象你说环境是重装了的，也许可以试试重装时有的东西变化到稍早的版本，再不然，仔细找程序中是哪个地方可能兼容性可以改善。
你可以看下别人程序通过的环境，版本具体与你的有些什么不同。
查看运行每轮时的损失函数是否在不断减小也可以先做做。别的机器能正常报告，说明你的机器绝对有问题，所以还是得想法缩小问题范围。
程序都因nan溢出而中止，而非报告错误而退出，最可能的还是应当是我最先说的那些问题造成。你慢慢找吧，再不然，初始化参数值时减小随机值的方差范围试试，你要别的机器上说不定是碰巧没出问题，其实也会大概率出问题呢。
再不然，那台能行的机器上，也可能已经有较理想的参数值了，你可以将那台机器上的保存好的训练结果给删掉，让它没有预训练，也从头开始。
赛道3
来呀
哪个队伍
 解决不了，我只用到detect文件就没管他
detect能看懂，train对我用处不大就没管了放服务器跑吧
detect能过，说明使用训练好的参数与正常影像是能过的，没溢出，那问题十有八九就是训练时没先读入训练好的参数继续训练，或者训练学习率过大或批归一化初始不对。
牛啊那我在去看看
我之前也是
欧美的人工智能那么厉害为什么却没有这种软件？是不是欧美的那些大企业不愿意公开出来？
而且这种合成歌声软件又不是人工智能，是采纳现实中的人声素材，再用软件把声音素材合成一首歌
估计欧美人不喜欢电脑合成的歌声
最近几年不是已经有用ai算法合成人声歌声的引擎了吗？
之前看了欧美孩子对这类软件的看法，他知道这是用电脑合成的歌声后说：这不是真正的音乐，我再也不想听了"
你说的那些欧美小孩接触到的这类软件是人工智能合成人声歌声的引擎还是像袅袅歌声的那种引擎？
他们只知道这是用电脑合成的歌曲，并不知道这歌曲是怎样用电脑合成的，好像还以为是ai。所以都一样
他们只喜欢听人唱的歌，觉得电脑唱的不是真正的音乐
确定这不是囸本的吗？
我只是查到，当时并不知道这是哪国的╮（╯＿╰）╭
所以你要用的话就用国产合成歌声软件Synthesizer V吧
下面那层楼突然没了
你用Synthesizer V吧，这软件合成的歌声超好的，调的好与人声几乎没有分别
你可以B站搜索诗岸，听一下这软件合成的歌曲
七楼不是好好的吗？
我这里的显示不出来那层
你直接用Synthesizer V
Synthesizer V很好的
我刚才查到了微软的小冰，这个和你推荐的那个那个比较厉害？
小冰是AI，不是合成歌声的软件
ai就不能当做合成歌声的引擎吗
我在网上看到有人用小冰合成歌声
查到了，那个叫X studio
不过看样子，主要研发好像还是由中国人
X studio歌手，这款软件跟其他歌声合成软件一样是通过声库和编写乐谱来唱歌的，AI起到了读取乐谱的作用。不过这个应该很少人知道，请原谅我的孤陋寡闻
再举个例子，自由意志是否由诸多基元构成？如果你承认，那你的自由意志能否无限分割得更小，直至最终，在某个基元里就一定有独立的自由意志。
自由意志，对一个有冗余的主体来说，肯定可以分割得更小，但这种小，绝对是有限度的，并且是有替代的，例如这块不要，另一块补上来，可能也能形成有所不同的自由意志。最后，强调一下，所谓自由意志的自由，只有相对自由，没有绝对自由。
相对自由，你可以说它某个尺度上，没有自由，都是前因导致后果，换个尺度，也可以说有一定自由，因为不确定性、熵增的存在。
不确定性的存在，是绝对的。
的确，大系统的功能，可能不是有单个子系统构成的。但是，大系统的功能。要么是子系统的单独功能，要么是多个子系统共同作用的结果。比如，读书。这是人这个大系统才能完成的事。子系统是不可能单独完成读书这件事的。单独的，眼睛，嘴巴，是不会读书的。
但眼睛嘴巴等器官结合，形成人这个大系统。人就具备了读书的功能。虽然，单独的眼睛不会读书。但读书，必定是建立在眼睛嘴巴等子系统的基础之上的。所以，大系统的功能，要么是某个子系统单独具备该功能。要么是多个子系统共同具备该功能
就像读书，看文字的功能属于子系统眼睛，同时，看文字的功能，也属于人这个大系统。但读书这个功能，属于人这个大系统，不属于组成人的任何一个子系统。可是，读书属于人体的其中一部分子系统的功能。
所以，可得出结论。大系统的功能，要么属于单个子系统的功能，要么属于多个子系统共同作用的功能。自由意志，是人的功能。它要么是一个单独的子系统，独有的功能。要么是多个子系统共同作用的功能。
如果是单个子系统的功能。那就像，我说的那样。存在意识核心。如果是多个子系统共同作用的结果。那么，自由意志。不可能在一个子系统里面找到。它只可以在多个子系统里面找。
可是，即使是单个子系统，他还是可以看成是一个大系统。比如，大脑是身体的子系统。但大脑相对脑细胞，它又是一个大系统。因此，自由意志，不论是多个子系统组成的，还是有单个子系统组成的。
它都可以说成是，有特定功能的系统组成的。如果，没有这个特定的系统。那就不能说明，人有自由意志。我说的意识核心，你可以把他理解为子系统，也可以把他理解为大系统。如果，人类没有这个功能的系统。那人的确不能说是有自我意志
就像，人没有眼睛，没有嘴巴。他能完成读书的功能吗？读书虽然不属于，嘴巴，或眼睛的任意一个子系统。但他属于眼睛和嘴巴等子系统的集合。这个集合，属于但不等于人这个大系统。而能实现读书这个功能的多个子系统。我可不可说它是一个人体的子系统呢？
自由意志，也是如此。它可能不属于一个单独的子系统。但他必定属于一个有特定功能的系统。这个系统可能是有多个子系统组成的。但他还是可以称为是一个单独系统。
可以加个联系方式，一起讨论啊
自由肯定不是绝对的，肯定是相对的。我想表达的意思是，人的感受是可以拆分的。感受不是一个不可分割的整体。就像，人没了眼睛就感受不到多姿多彩的世界。同样的道理，人们能感知外界，能下达命令的那个存在。肯定也是大脑的一部分
这一部分应该是可以剥离出来的。就像视觉系统一样。没有视觉系统。我们就看不到世界的颜色。没有感知外界，和下达命令的那个部分。人就不可能感知到外界，也不可能下达命令
当然，这个下达命令和感知外界的存在。肯定不是不可再分割的。就像视觉系统一样。它有自身独有的功能。但他是可分割的。视觉系统，包括眼睛，包括视觉神经等。那个能感知外界，能下达命令的存在，肯定也是像视觉系统一样。有自身独有的功能。但它是可分割的
人是肯定有感知外界这个功能的。也肯定是有下达命令这个功能的。只不过，感知外界和下达命令的系统不知道是不是一个系统。当然，目前发现的下达命令的器官是大脑多个部位。我说的这个下达命令，是在感官器官在接受到，会不会有一个单独的下达命令的器官。
大脑肯定是可以下达命令的。但大脑下达的命令，也是一个混合的命令。比如，人饿了，一般都会主动去吃东西。但是人也能在饿的时候，忍住饥饿的感觉。这说明，人体在执行命令时，他是在执行最少两个命令。一个是，去吃饭的命令。一个是不去吃饭的命令。
既然，人体执行的大脑命令有可能是多个。那就表明。大脑能下达命令的部位不止一个。
至于人体会执行那个命令？肯定是两个命名共同作用下，会形成一个综合命令。人体只会执行综合命令。而不是大脑的单个命令。既然，人体执行的是混合命令。那就可能存下一个感知外界，并下达命令的存在。这个存在就是灵魂
首先，视觉，嗅觉的确可以看成是电脑的输入输出设备。这些设备坏了。不代表灵魂也就是意识核心坏了。但意识核心坏了。就像电脑的核心坏了。没有电脑这个核心，只有输入输出设备。人体就真的惨废了。
如何确认是输入输出设备坏了，而不是核心坏了？只要你还有意识，就表明核心没坏。检验核心没坏的方法，那就是看核心能不能正常运转。能正常运转，核心就没坏。人的核心就是意识。如果去除输入输出设备，人还有意识，则说明，核心没坏。
而核心没坏，就是加入记忆，加入视觉，加入气味等输入输出设备，人还是人。这就行了。我们可以做思想实验。
至于灵魂是否包含在其他部件里面。也就是说，灵魂会不会包含着记忆，视觉等器官里面。我没说灵魂不可分割。如果灵魂是包含在视觉，听觉里面的。那就表明，人没有灵魂核心。这个灵魂是分布在其他器官系统里面的
如果人有灵魂核心。那他比如是去除嗅觉，视觉，记忆等事物之后，还有完整的核心存在。这也是我要表达的意思。如果有灵魂核心，则说明人有自主下达命令的存在。这个存在就是灵魂核心
 人自主下达命令，情绪会给人下达命令，人也能为了命令而命令，这算自主吗。人识别了命令是什么，比如通过对具体命令的描述，然后构建了命令的概念。命令是让他人或自己完成目标。目标是完成事情（当然可以随着理解加深加广）。这样人就能让自己产生目标。
最初的命令可能是情绪给的，或别人给的，只要人能够识别了命令是什么，能够理解命令语句，那么人就能自由产生命令，也能自由执行
我只是单纯的谈论意识。在我看来，要么存在意识。那他必定是一种物质。一种可以感知外界，并下达命令的存在。要么不存在单独的意识。他是存在于多个大脑子系统里面的。如果真有意识核心，那认识意识容易。模拟意识核心也容易。但制造完整的类人的意识是困难的。
因为，意识核心如果存在。那他不过是一种物质。一种可以感知特定信号，并下达命令的存在。人类只要找到这种物质。就找到了意识。这个意识，也不是目前人类可以变程的。它也是如心脏一样的存在
人类只能把他取出来。然后，把他当成特殊的一种可以释放命令信号的物质。且这个物质可以感知特定的信号。
在我看来，人即使真的有意识核心。但人类要想制造出类人的大脑。还是十分困难的。造不出类人的大脑。找到意识核心，依然制造不出类人的机器生命。
你微信多少我加你
“只要你还有意识，就表明核心没坏” ？做脑瘤切除术的人，多多少少都会被破坏一些正常的脑组织。术后通常感觉不出有什么变化，那是因为还没遇到恰巧能触发受损部位的事件，这核心算坏了没坏？对于大脑这样一个超级并行网络处理系统，坏掉多少个意识反应算坏？
如果不能接受外界信息，那么人还是有意识的，人能想象很多情景，人能幻想和构造各种情况，人能想到一个人走路时会碰到什么危险，这是同外界没有交互的内在意识
意识没有核心，它是由无数个意识反应聚合而成的。而每一个意识反应又是由具体事物的认知处理过程抽象而成的。
没有听觉的人，用手语思考，也用文字图像思考，没有视觉的人，用声音思考，他脑中的信息不是图像，能够识别一种信号，并关联到其他信号就是智能，关联多种信号就是强智能。 智能包括预测和描述另一个信号系统，并统计其他信号系统的规律。情绪系统有其自身规则，也是一种独立的信号
这要看你扣掉芝麻大的电容是在哪里。如果你扣掉的是显示器上的电容，且是可以影响显示的。那就表明这个电容是，显示屏的核心组建之一。如果是电脑核心的电容。那么去掉会影响电脑核心的运作。那说明这个电容是电脑核心的组成部分
所以，你扣掉的电容。要看他影响了什么功能。影响了什么功能，就决定着他是那一功能的组成部分。同理，意识也是如此，通过扣掉那一部分，影响了什么，可以判断他是那一部分的重要组成成分
电容的功能一样。大脑的组成成分，都是物质。说白了，如果有意识核心，也不过是一种物质罢了。物质的特性也是相同的。但他处的位置不一样。功能就不一样。扮演的角色就不一样。
是物质就有物质的特性。但他同样的物质，处于不同的环境里面，他的角色就不一样。同样的电容，功能一样。但他处于电脑核心和处于显示屏核心。他的角色就不一样。一个是电脑核心的角色 一个是显示屏核心的角色。所以如果存在意识核心。他应该也是一种物质。甚至就是一团神经元。
所以，我们也许已经找到了这个所谓的意识。只不过，我们不知道他就是意识罢了。所以，在我看来，意识不难找，难的是，我们看到了他，但却不认识他罢了
马克思主义在没有得到实践之前。他难道也是官哲吗？爱因斯坦，没成名前，他难道也是官科吗？我并不觉得民科民哲丢人。只要说的在理。能得到证实是正确的，是否是民科，一点都不重要。
“这要看你扣掉芝麻大的电容是在哪里”，你对电脑都这么清楚了，那么你对人脑是否也如此的清楚？如果不清楚的话那就是盲切咯[滑稽]
这个不需要对大脑的功能有多么熟悉，你找一个不了解电脑的人。你扣掉显示器上面的重要电容。显示器就不能正常工作。你扣掉电脑核心的重要电容。电脑核心就不能正常工作了。只要是人，即使不知道电脑的工作原理。他也肯定知道。被扣掉的电容的作用
是人都知道，扣掉的电容如果让显示器不能正常工作。那这个电容肯定是显示器的重要组成成分。如果扣掉电容，电脑核心就不能正常运行，则这个电容是电脑核心的重要成分。人脑也是如此，那一部分受损。人就丧失哪一种功能。
受损的部位，就是被拆掉的功能。
https://www.zhihu.com/question/392867244
这能说明什么呢？就像电脑扣掉一块，也不见得，电脑就不能正常运转了。即使是电脑的核心，也不是不能扣掉一些不重要的物质。
沟通好难啊！这么说吧，你认为切掉的东西会影响到某一项功能，但事实上可能没受影响；你认为不受影响的东西反而可能影响很大，这是为什么？其实这完全取决于你对它的认知是否全面且透彻，你很清楚大脑的结构和功能吗？
之所以这么强调这个，是因为几百年来西方科学界的成果基本上都是切出来的，这条路在寻找灵魂方面是行不通的。
既然你认为沟通困难。那我也就过多不解释了。因为，你根本没理解我的意思。等你真的理解了，就不会有这样的疑问了
我有时候，理解别人的意思，也不是一时半会就能理解的。需要过一段时间。甚至，不理解对方的意思之前，还反驳或嘲笑对方。但当真正理解之后，就会觉得当时的自己很好笑。
世界是物质的还是非物质的已经有定论了，再讨论这个是浪费大家精力和时间，意识和能量一样不会凭空产生，也不会脱离物质依赖，意识依赖物质社会发展，不断的认识学习积累出来的，我给你举个例子你就明白了，婴儿刚诞生出来，我们会认为他有一点点意识的
因为他会对物质世界做出一些非条件反射的一些反射了，饿了会哭难受也会哭，希望获取父母的关注度帮他解决饿或者难受的问题。随着长大不断的加强认知能力，不断认识学习物质世界，达到甚至可以改造物质世界，他的意识会逐渐成型，包括人格，性格，认知能力，思维方式等
你有没有思考过。为什么人动脑筋的时候，我们会产生思想，会有思维活动。但人不动脑筋的时候，人就不会有思想，有思维活动?
而动脑筋，必定伴随能量的消耗。总结一下，就是人类有精神活动，必然离不开能量的消耗。这说明什么？
再加上一句，脑袋没有发生能量消耗。那大脑必然是死亡的。死亡的大脑是没有精神活动的。这有说明什么？总结以上两个观点，人的精神活动，离不开能量的变化。能量是物质的，精神活动离不开，物质变化。这说明什么？
意识成型之后，比较难改变的了之后就是学习积累了，如果非要强行改变，很大可能比如遭受重大精神打击，就会出现精神疾病比如幻想妄想精神分裂。所以意识成型后是比较难改变的，有个词来描述就是本性难移。说这么多，要表达的就是意识是物质为前提不断的学习积累形成的
这就是说明精神存在的前提是物质存在
你说的意识和我所说的意识不是一个东西。只能说相近。我说的意识，是在通过大脑的功能，在剥离意识核心，就像我说的是电脑有没有CPU。你说的意识则是如何组合CPU，硬件，形成电脑
我说的的电脑的核心是什么。你说的是，电脑是如何组装而来的。电脑代指意识。
那我在加一句，意识能操作人体。这说明，精神可以操纵物质。因为意识是精神的，人体是物质的。这又说明什么呢？加上，精神需要物质基础。这两者说明什么?
过程，现在人们讨论人工智能很多都脱离这个过程，而不是说想凭借某一个强大的图像识别，或者一个深度学习算法，在某的一瞬间啪 智能就产生了，不可能的这是，就像是一个刚诞生的婴儿但是却有一副20岁的身体，有最强力的大脑，有敏捷的四肢，有不模糊的眼睛，但他的意识水平还是0岁
我认为，精神离不开物质。精神又能操纵物质。这就可能推导出一个新的结论。物质和精神是同宗同源的。两者是可以相互转化的。因为，物质可以操纵物质。就像机器人，可以操纵汽车等物质。机器人也是纯物质的。所以，精神和物质，极有可能就是同一种事物。
我们非把精神和物质分开来讲。本就是一厢情愿的做法。我们说精神和物质。只是因为物质和精神给我这个意识的感受不一样。所以，我们才有了物质和精神之说。但是，给意识不同感受的事物，未必不是一种事物
就像，带着有色眼睛看世界和不带眼镜看世界。世界给我这个意识的感受是不一样的。但世界本身肯定是没有变化的。世界就是世界，他不会因为人带来眼睛就改变。所以，更多的可能是，世界不区分精神和物质。之所以区分，只是人对同一个事物有了不同的感悟认知罢了
所以，在我的眼里，意识其实也是物质的一种罢了。只不过，意识是意识自身直接观察得到的。物质则是意识带上了眼睛看到的其他类似意识的事物罢了。
你说的这些不就是主观能动性么？意识能认识世界，在认识的前提下能主动的改造客观世界。这不是什么新结论，这些马哲里面早已经有了
马哲的观点意识和物质是两种事物。而我的观点则是，物质和意识可能是一种事物
我建议你抽时间把马哲看一遍吧，不要在意识还是物质的事情上浪费精力了，我还是希望吧友们能多讨论一下 形成智能需要的一些本质条件
要不你去查查马哲的 一元论 吧 我觉得你真的没有自己看过马哲 你可以看一下跟你说的 物质和意识是一种事物 是不是一回事 听我的建议，自己不要思考物质和意识了，去看完马哲 你会对世界的认知水平提升超越普通人的
哪有时间看马哲啊！我知道一元论。但是他们所说的一元论。要么世界是物质的，要么世界是精神的。但是我认为，世界既是物质的，也是精神的。精神和物质是一种事物。那么世界就不可能只是物质的，也不可能只是精神的。而是精神和物质两面一体的。
你应该是一个十足的马克思主义信奉者。但是，我不是搞哲学的。我思考这些纯粹是业余爱好罢了。不是干这方面工作的。不考虑这些事情。其实，经你一说。我也感觉，马哲的确有道理。虽然，没真正接触过哲学。但是多多少少了解过
你知道什么啊？你什么都不知道，一元论的重点是世界的本源！本源！本源！不是说到底是物质还是意识的问题！你说的那个 世界是物质的是唯物论， 世界是精神的是唯心论，这俩种都属于一元论的！不管唯物论还是唯心论都认为世界是一元论的！
我其实是一元论的赞同者。我知道一元论，讨论的是世界的本源。我对本源也有过一些思考。
我认为，世界的一切都是本源演化的。而不是一个特定事物就能代表本源。假如能量是本源。那他只能是本源的一部分。本源应该是所有能量及能量的演化物的组合
一元论说的是世界由一种构成的，唯物的认为是物质+意识是由物质构成的，唯心认为是意识+物质是意识构成的。二元论认为世界是物质和意识构成的，多元论认为世界是物质+意识+其他构成的 懂了吗？不是你理解的马哲只有唯物论唯心论俩种
一元论说的是世界由一种构成的，唯物的认为是物质+意识是由物质构成的，唯心认为是意识+物质是意识构成的。二元论认为世界是物质和意识构成的，多元论认为世界是物质+意识+其他构成的 懂了吗？不是你理解的马哲只有唯物论唯心论俩种
你说的这些，我知道啊。
我用能量，只是打个比方。我一直认为世界是一个整体。世界是唯一的本源。意识和物质，应该是一种事物的两面。这个事物，既是精神的，也是物质的。精神能转化成物质，物质也能转化为精神。或者说，物质和精神的中间态是世界的本源态。
本源态是世界的一种状态。不代表就是本源。比如意识是世界的本源。那世界的本源就是所有的意识和意识产物。意识只是本源的一种状态。可以称为本源态。但他代表不了整个本源
为什么这么认为，也可以给你说明原因。但是，不是一两句话能说明白的。所以就暂时不解释了。有这样的说法，也是有原因的。
哥们，我觉得我们讨论已经有没意义了，我抓不住你想表达的具体观点，似乎你一直在解释物质和意识之间的关系(很多观点也不对)，我最后表达一下我的观点吧:人的意识不会凭空产生，依赖物质存在为前提，产生形成于后天的社会实践中。你查 狼孩 人类社会对意识影响多大
我们表达的看似一样。其实是不同的内容罢了。无所谓对与错。
非要说谁对谁错，只能说明，彼此没有完全理解对方的意思
你认为的意识是人类独有的意识。狼孩不算有意识，或者狼孩的意识有残缺。但我说的意识，则是那个能感知外界，能给人体下达命令的那个存在。能调用大脑不同功能的存在。狼孩在我看来只是心智不健全。但他是有意识的，且意识是完整的。
马克思是人，不是神仙。我可以参考他的哲学思想，但我不会照抄。照抄就是愚蠢。
那要多好的天赋呢？怎么看天赋呢？ 我数学平时作业挑着做，上课不怎么听，考试能考130算天赋吗？
不算
需要看透事物的本质，如犹太三巨头那种，你自己去了解下
没这么夸张，普通人只要愿意学，高收入肯定没问题，创业就太难了，现在各行各业都资本侵入的厉害，自己创业再好最后也是大厂的韭菜
解决了吗，老哥？[泪]
难点是如何发展。其实人脑的神经元网络中的神经元都可以看成是一个模糊逻辑的算子，数字计算机的底层是二值逻辑的算子。虽然二值逻辑通过一定的逻辑运算方式，也可以组成模糊逻辑的算子，但是结构是复杂的，而人脑的神经元是一个模数结构的模糊逻辑处理的算子，将来用忆阻器来进行，理论上就要简单的多
要知道人脑的神经元不是简单的“与”或”非”而是可以通过学习构成一个能够进行模糊逻辑处理的算子。人工智能和人的智能我在上世纪七十年代就已经开始研究了。我知道人工智能完全可以像人的智能那样的进行处理各种问题。因为我对这个有着非常清晰的认识。
我感觉意识的本质的语言，动物的意识不连续，动物认知到知识和环境的能力也是断断续续，不像人那样可以一直持续的有认知，有智力和分析，动物的分析是偶尔存在的。人的分析和语言有关，人的意识核心是语言。 人能够让自己时时有了分析，时时有了意识活动。意识是对本能的利用和应用，
字词本质是明确的机械操作。“看到”的含义 环境作用于眼睛后，眼睛中出现的信号。味道的含义是 用舌头作用物体厚，舌头的变化情况。 我视野中的物体 也是眼睛中得到的信号。盲人理解看到和视野就是通过理解这些物体之间作用而理解词语含义的
指代一个物体时，除了使用名称外，还可以通过和其相互作用的物体来指代。比如说那堆柴火，可以说刚刚我用斧子劈的物，比如说山，可以说我刚刚用眼睛作用的那个东西。完全不必说物体的名称。说某种气味和颜色也可以说我闻到，我看到的信号。
对于没有味觉和视觉的人来说，就能对语言有这些角度的认知。 高度是通过尺子处理得出来的数据，语言对应明确的物理操作，结果可以从作用体中去寻找
我本文中说的意识是指定义能力，说的任何概念可以通过描述而具备，而描述能力具备了，就具有意识。 描述能力如何具备就是另一个问题了。 这是从某种角度定义的意识。人的各种描述能力，对各种现象和情况的描述甚至分析能力定义为意识的本质，甚至定义为意识。
趋利避害不是本能，而是欲望。本能是先天具备的能力，能力和欲望，是两回事。欲望就是欲望，能力是你去满足欲望的本事。
自我保护的工具开发得足够强大就是智慧了。动物也有自我保护的本能，可是方法太差，
但我们得承认，动物有自我概念，比ai强一个层次，ai没有自我，也没有自我的念头，没有办法用工具为自己谋利。
你应该看过海尔兄弟吧，里面有个智慧爷爷，每当海尔兄弟有什么麻烦都会求助智慧爷爷，然后获得方法解除自身遇到的麻烦。那么你看的时候有感觉到违和感吗？如果没有，那么你潜意识也是将智慧与意识分开看待的，不是一体的，如果有违和感，当我没说 
其中解决麻烦的方法是智慧，是经验的积累（自己的经验与别人的经验）。
智慧爷爷做了啥呢，首先它接收到海尔兄弟的需求，然后想出解决问题的办法，这就是意识平常做的事啊。你想一下，要是智慧爷爷是个植物人，他能做到这个吗？
没有意识或者说智慧的话你怎么保护自我？
保护自我是欲望，欲望提出需求，智慧来想办法实现这个需求。
那么就得说说怎么让"自我"觉醒了，我隐约感觉生灵有被设计之感，首先要有自然物质构成可活动的躯体，即，类比人的身体，二，能量源及配套的能量循环通道，类比人的心脏，血管，三，收集自然属性的"五感"（虚数）器官。
前三都是物质能表现出来的，四，自我的灵魂空间，（重点是这个）我在开一楼
论述的挺好。不过标题应该改成：汉字中的动词是名词的组合。
既然要想电脑具有学习功能，那就需要具备会辨认库外的东西，并决定是否将这个东西纳入库内的能力。字库是基本固定的，但是词语具有更高活性，句式活性更高，同一个意思有数十种表达方法。
还有关系。人类的创造力就在于创建事物之间的新关系。而这个新关系并不存在于原先的图谱（或者库）中，人类看待这个新的关系，并决定将它纳入新的知识体系呢？
字词句章所体现的都是一个共同的东西：究竟什么是学习能力？很明显搜库不是。搜库只是回忆。知识是何时如何到我们的脑海中的？我认为这是最需要考虑清楚的问题。之所以从字开始，不是为了钻木取火，而仅仅是字是这几个里面最简单的。
而且图文字的东西搞清楚，你就有一款100%精度把PDF或者手写转成WORD的软件，马上就成果落地了。
有目地性的做出选择，也是意识的一种表现形式
[呵呵]，没错，但是这么写也有点别扭，看起来好像变成字是词的组合。
我的思路一点点都不发散好吧。最近两年一直在思考知识图谱的结构问题，所以很少来论坛。三元组什么的太简陋了，不足以形成整个知识网络。那么知识图谱最中心的节点到底应该是什么？
越是深入思考，抽丝剥茧，越会追寻文明文字的发展历程，毕竟人类文明不断生长的过程，就是图谱学习和扩充的过程。这是自然的老师。
【一个成型的图谱和语法分析都做不出来】，没错，一个成型的图谱到底是什么样子的呢？别一说就依靠图谱读取啥啥啥。这个可用的图谱到底是什么样子的？树状还是中心簇状的还是离散的？每个节点处是些什么东西？这是我最近两年一直思考的问题。
这个可用图谱中最基本的元素又是什么？包含字库词库属性库等等一系列的库吗？如何将万事万物各种知识容纳在一个有限的图谱之内？又该如何定位和检索？如果去搜寻整个图谱，算力该如何？这些东西对我来说太难了。所以确实至今还没有完全成型。
编译原理都不懂。。。
我也在想这个问题。
小唯看起来是个刚学过编译原理的学生，肯定是学的不错。
趋利避害也有等级，动物趋利避害能力很差。动物不会主动想象，不知道想象和假设的作用，想象和思考可以起到趋利避害的作用，甚至可以创造出无限多种趋利避害的方式，这种创造和联系的过程就是意识。 分析也包括 考虑任何一个动作和行为或者想法是否能够起到趋利避害的作用
趋利避害是一种开放的功能，甚至是人可以无限优化的功能。动物的趋利避害是低级的，不能发展的，动物不能创造各种趋利避害的方法
我做yacc不到500行python。
“自我存在”我和你理解的角度完全不同。自我是一个指代功能词语，是寻找声音发出者所对物的处理，存在是在世界上存在，而不单单是在脑中存在。 自我存在是两个属性判断的处理。 判断说话者对应的主体是谁，之后是判断这个主体是否只在脑中存在，
而且人无法准确判断一个物体是否存在，因为有的东西存在可能只是一种幻觉，当然还需要去摸一摸，让别人看一看，才能肯定物体在环境中存在，判断出自我存在
比如 属性是 1.7米，70公斤，如何通过和自我属性比对得出来呢
灵魂空间指什么？你想到了什么？把灵魂空间定义成什么样？空间通常是形容 没有物体所在的场所，灵魂空间是说 灵魂中的体积吗
 人工智能，走编译原理这条路不一定走得通。各学科，各种思考都可以借鉴，最后不一定谁能走得通。
不是，我的意思是，人可以理解动作，也可以手舞足蹈来表达一个动作，但是从文字来看，动作如何通过文字来表达，里面不含有关于“动”的基本因子，只有名词和名词的组合。关于“运动”的基本因子不存在于文字本身，而在人的脑海里。
 名词也是情景调用，动词也是情景调用。 情景中经常是多个动作，连续的过程，想要指代清楚，还要更多词语，甚至需要互相辨明，说出是哪个具体动作，具体动作可以通过特征来区分，只要你们心中都有了那个情景，比如说踢腿的那个动作，
动作被记忆后就存在于脑中，一个新的舞蹈动作不能被语言表达，连颜色也不能被语言准确表达，最多就是类比，像那种已知动作。几年前我就知道这个
 手舞足蹈不是一个动作，是舞和蹈的概括，舞和梦和劳动一样，又是动词又是名词。
举个例子，一款游戏魔兽世界吧，游戏人物是不是一个人形框架，它在里面能跑能跳，打架的时候不是设置好的自我属性与设置好的物品属性的碰撞吗，
 那是平面空间，人的想法不存在平面空间，但是有先后顺序，有相互关系。灵魂里也不是在平面上活动，是对信息关系处理的活动。
现在的的关键是，在物质界的躯体属性，与自然界的物质属性，录入游戏世界，外界的属性碰撞结果，投射到游戏世界，在物质界的属性是真实，在游戏界的属性是虚假，联动起来做不到到吗
 这种属性有什么用，平面属性的空间有什么作用，灵魂空间只是说灵魂具有平面内的被设置的属性，这有什么方面的意义呢
 不能录入，我琢磨过这个问题，完全不能录入。 物质的属性具有无限性，就像录入火的属性，可是火和外界一切物体作用后效果不同，火的属性只能火本体具备，录入游戏后，火和游戏中的各种对象作用后，这些物体不是物质，
不具备反应特性。 就像你研究药物，录入的分子组合后不能像真药一样，给具体的人甚至各种病治疗
 你录入氧气特性，录入氢气特性，但是如何让游戏中的对象反应产生水呢，录入的东西只是一种图像，录入的是信息，用编码记录的信息，
这些编码信息不能像物体一样发生相互作用，也不能体现出作用后的属性，更不能被测量属性。 你不可能对游戏中的物体用 火，酸，压力，光谱等等进行测量。
你想的东西我十年前就都想过了，而且也找到答案了
这个我同意，但是你说的，水，酸是可以跟物质界的身体产生反应，有结果，我们不需要在虚拟空间产生水，只要有碰撞结果，然后判断会不会对现实的身体产生危害就够了呀，所以就有了群体样本，
假如有个人碰到了酸，会损害身体，旁边的人就判断有害，然后就远离，或间接接触，虚拟空间的作用不是产出什么，而是记录在自然界属性与现实身体属性碰撞的结果
怎么利用自然界是下一个问题
只记录现实的碰撞结果
这个属性是动态的，1米这个属性是公共属性，在一开始的属性定义是属于私人的，比如一个矮子比划一个比我高这么多的固定距离的树，高个子比划的高度差肯定是不一样的
 能够测量才代表能够相互作用，记录碰撞直接用影视文字记录就是最好的，和虚拟世界无关。 游戏就不错，每次碰撞后就会出现规定好的变化，
 连模拟一滴水内分子的碰撞都难以完成，别说更高级物体的碰撞，地震也是板块碰撞，但是不能模拟清楚
我觉得你考虑的太深了，
自然碰撞就是最好的测量，首先解决个体存活问题，剩下的才是如何利用
 测量是 用工具和物体作用，通过工具的变化认识物体。碰撞测量物体的话，只能测出物体的动量，弹性，质量等，这些特性可以被测出，颜色和温度，用途，价格不能通过碰撞测量出来。碰撞当测量器的的价值很小，
我说话每个词都会追根究底，否则就没意思
噢噢噢
我们的系统是免费的，就一个电话费，方便留个联系方式详细联系吗？3114134780
可以
上面那个就是我的微信
有
NVIDIA
不考虑国产的吗
:公司产品正在逐步往这面靠
可是识别这些信号灯啦之类的，不就得对图片进行卷积吗？ 一张图片几千万上亿像素，一秒几十张上百张图片的。
是啊！所以无人驾驶改为有人看着了，就怕程序出bug活着卡住就装死人了
毕竟炒概念吗！比特币就炒的非常成功，带动显卡涨价，反正显卡老黄不市值蒸发80%我不打算买新显卡
一张图片你会怎么分辨？红绿灯是连续性的，就那么几种方式，障碍物移动和固定两套区分程序就好了，硬盘存储着这些东西模型特点对照一下就好了
疫情共存就相当于说，得病自己死了活该！反人道主义，最近爱狗爱猫智障都不哔哔了，反抗病死了活该我要活着了
那是不是如果学人工智能的话，就不要去学sql，只有大数据需要去学 
好的，谢谢老哥，我目前走人工智能的话就是准备走cv或者nlp的，感谢老哥的点拨
嗯嗯，我本科虽然学的是嵌入式，但是也是有学c和汇编的，老哥我想问问对于人工智能是不是学c++要好于java  ，还有就是双非硕士的话进人工智能是不是没啥优势呢 
V：a13716368357
怎么骗的啊，是深圳的那个吗
这么说就是还不错喽。数学天赋这玩意，我应该算是比较高的了，一千分之一的那种。我是想着多学一点，以后留在深圳自己创业，又能赚钱又能研究自己喜欢的东西
或者往更高层次设想，利用宇宙线辐射和各种高能带电粒子、等离子体。作为动力呢？
看原来数据分析、现在人工智能在各方面研究上，包括生物科技、药物开发、化学上的全面应用就知道。不懂它不会用它或与人协作用它，就边缘化，就淘汰。
不懂没关系，至少能与懂的人协作，做好协作，也勉强能行。
逻辑能力系统，一般都会学一些逻辑能力的东西，例如逻辑基础、一阶逻辑、推理，很多书里都有，甚至学电子、自动控制、计算机软硬件，逻辑都是基础的东西，说一点没实现肯定不大对，智能上，做得最突出的就是逻辑推理应用能力。
我说得把空间分成小网格，物体照常识别啊，空间分成小网格只是为了知道物体距离机器人的坐标距离
请教一下，为什么这里都是机器学习有关的内容?机器学习只是人工智能的一部分吧
这个贴吧为啥没什么人讨论问题。
我没那技术啊
层主是个实干人才。看来对视觉和听觉研究很深 
😓其实就是个小作业 随便什么方面的应用都行，我学计算机的
那太多了，例如：由人给出的需求设计，不算顶级的人工智能自动给出后面要做的所有能随时因整个团队及外部交互而动态响应的流程、人力资源分派建议及可参考信息（到处去爬取、挖掘加工信息并整合）。顶级的，更合理详细的安排、信息整合与响应及远少于前者甚至只要极少量人员参与的设计系统。
贴近于人们生活所需的，更高级的垃圾分类、垃圾处理、智能制造、家庭卫生服务、餐厨服务，医护服务。
你现在有可能做好的：楼道自动照明系统，这个网上去搜，以前声控，你可以加上红外摄像头、神经网络以实现高准确率、自适应或可根据录像偶尔校正样本以提高实际场景准确率的照明。
最好是低分辨红外摄像头，以免隐私问题摊到自身来。且附近传感器数据多个多批组成批量数据到神经网络，可以不用循环网络，训练时自然有历史信息，出来的结果有时空相关性，判断是否需要照明，更为准确。
其实我已经想好方向了， 就是如何利用人工智能 降低服装设计或平面设计等的门槛，让普通人根据自己的想法粗略设计鞋\\服装\\海报\\插画等 而不用懂那么多的软件操作 专业知识等等 这个过程有什么好的优化方式吗
大一我连API都不懂，这个作业主要是创意设计 不要求实现 要是自动照明什么的感觉太单薄了
这会不会太局限了 我的想法可能过于理想化 就是从现实中抽象出设计对象（二维或者三维都可以）比如说有一双鞋 用目标检测找到 再用什么语义分割辨别鞋带 鞋垫等等是什么样子得到这些数据 然后在设备上做修饰调整等等 现在的人工智能能实现吗  大一真的啥都不懂  对难度也没个概念
为什么不能二维三维都能设计呢😥
很多原因，最直接的就是专业性太强。然后真有问题也不是那种只言半语能讲清楚的。还有卖课卖资料的一堆
设计鞋的，都是三维，没有还用二维模型去设计的。
那就是二维设计吧，效果图 产品个性化定制 这个过程怎么简化 尽量简单又能让人工智能尽可能多地满足个性化？
三维，一般的三维设计软件都支持命令行操作，简单点，就是想法将一般的设计过程都弄成模块化参数化的命令行块，个性化就是匹配不同模块不同参数的人机交互的接口设计了。
人机交互的接口设计中，你可以加入人工智能的更多特性，例如机器对人的意图及可选工艺、材质、色彩的理解、尝试使用自然语言理解、神经网络解析、生成等。
不是生成全新的材质，是选择已有的进行空间组合，这样的有限的生成。
例如部分鞋面用什么材质，另一些区域或曲线用什么，进行创新、合理、有约束的组合，给出一些设计者倾向前置条件下得到的可选方案，再由人机交互迭代精进。
某些情况下可以用条件生成对抗网络等进行人机交互设计过程的迭代参与，这应当是较常见的手段。
但它只是局部、高可用时的部分有用辅助组件之一，不能妄图全都用条件生成对抗网络做大部分工作。因为它限制性、专用性太大，且一般要求架很大个势，花较大量的数据准备与训练成本。
真想搞，应当学一些计算机辅助设计及要用于设计的软件的底层机制、插件机制等。
同时还得会较多的人工智能的东西。
要不断积累，主要有知识广度，也要稀疏有知识的深度，至少需要时能快速评估并捡回来真正需要的。
目前是基础知识储备都没有创意设计， 不过我也是想的参数化设计，把软件操作封装起来，非常感谢！
请问大佬 现在我要训练一个算法模型 这个算法能够根据人的 指令 调用一些包装好的软件（例如ps）指令块并且使得操作的参数在合适的范围 要用深度学习框架（百度飞桨）的哪些模型？过程是什么（比如数据集标注 等等）如何表述？
大佬 我在楼下发了设计的流程图 帮忙看看有什么算法模型可以用（不用具体实现，只要模型训练的流程等） 小白上网学习半天还是思绪混乱 无从下手
大佬 我在楼下发了设计的流程图 帮忙看看有什么算法模型可以用（不用具体实现，只要模型训练的流程等） 小白上网学习半天还是思绪混乱 无从下手
描述性数据分析的中间结果，用户才方便同样使用描述对初始要求、推荐进行配置、修改，这样，非专业的人员，仅需要自然语言或机器给出的一些选项就能进行设计，这才是未来自动化设计的较高级方向。
中间结果改成中间表述
再有，中间的参数，允许有的通过可视化图形gui进行调整，这个应当是友好界面的基础，就象色彩调整，颗粒大小调整，腰线什么的。
感谢大佬 
做标记啊，每件事情人都需要无数次的学习，机器人可以做标记，标记做了下次就会了
直播搞不来啊
写程序更不会啊
我对rgb颜色与反光之间的识别搞不懂，而且对几何图形了解得也不多
从不会到会都有过程，最简单的，手机买个架子，固定在架子上，对准某些有活物的地方，调好远近大小方向后，点都别动，一直拍，拍完了再剪辑。例如你本来就在农村，可拍的活物多了，管它最后有没吸引力，发出来给别人看，别人觉得好，你多拍点别人觉得好的风格的，自然就越来越好了。
镜头别在拍摄时跟拍啊，点都别动，初学者就是不懂这个，拿着乱晃，看得人头晕。
我不知道从何处开始，而且我那么懒，不想拍啊
也不知道该拍些什么
科技问题也不想搞了啊
咦，你是那个群里面的吗？好有缘啊
我可改变不了

糟老头子，坏的很
你不是说你不在研究人工智能了吗
我没研究啊，你个糟老头子果然坏的很
糟老头子，加个微信不
噢噢噢
 频率是指两跟线的正负电压一秒钟的（交换次数*2） 高频转换效率高是因为底频（即工频50hz）的变压器用的是硅钢片导磁，钢导电，有涡流，高频用的是铁氧体导磁，完全不导电，工作频率可以开到40KHZ， 如果开关mos管寄生电容解决，也可以进一步开更高频。
 同样绕线圈数，导同样的磁场强度，50hz 与50khz，相差1000倍，产生的电压就相差1000倍。
输出同样的电压，高频变压器可以绕线圈数很少，那么就可以用很粗的铜线来绕。铜线粗内阻底，损耗就小，转换效率就高。
 50khz 不再高进一步提高工作频率。原因是晶体开关管的通断速度跟不上，就如Cpu工作频率高，发热大，不稳定，容易烧。
噢噢噢
涨知识了
噢噢噢
 普通变压器初级两千圈，铜线可想有多细，高频变压器，只是缠绕上20圈，可以用很粗的铜线，同样是接到峰电压300伏上。
，几乎一瞬间，电流极速增高，开关管就把电初级给断掉，副绕组马上产生电流，并且接管初级绕组通过开关管输入的磁场的能量。转换速度非常快， 需要芯片测量电压计输出能量的大小，来控制开关频率和间隔时间。
确实，在外侧移动，所以很多高频变压器都是用很多铜线并在一起作为一根。
噢噢噢
吃汉堡还不如去点菜吃
你明明说你是富二代，你还缺钱
磁的本质是电子的圆周转动。磁材料是电子绕质子转，大部分同一个方向。当对转动电子有作用力的物体横穿过去，就会被转动的电子带偏。
对，这是引力波
噢噢噢
加1 
对啊
噢噢噢
是的 有自然规律约束
类神经是指深度学习网络吗
 包括神经网络和仿脑计划
类思维有哪些派别
任务树/需求链的，联想/状态演化的，思维指令的
有名的有全局工作空间理论，但是我不了解
而情感应突破心理学传统定义，语言表述上有些喜好、习惯其实也是情感系统在管理，例如某人不时就感到想喝茶，别人说他有喝茶习惯，其实是一种情节。所以，不仅仅是欲望，情感、习惯、喜好也是动力，但这时也可以说他临时产生了喝茶欲望，而这个欲望是他的喝茶情节引发，即整个层次情感欲望系统作用。
图像识别不是对比 在这里请你注意你的解释 谢谢不要误导别人
有兴趣加入群里常聊吗
多和复杂的确是两回事，但多并且实现了复杂的功能，那样的多和复杂就是一回事。你举的例子里那本书并不能实现复杂的功能。
冗余自然是有的存在冗余并不等于不复杂，生物有代偿能力，大脑的冗余可以代偿用以应对某些损伤，但未损伤时，冗余部分在做什么？大脑是个高能耗器官，这样的器官不会养无用细胞，我猜测大脑的冗余是潜意识的来源。大脑的功能不只调控生命活动和主观意识活动，更有尚未探明的潜意识。
机器也可以很复杂 只要开始了进化
兄弟 你研究范围挺广的
请问中医有类似的ai吗
请问有希望做出中医ai吗
有适合的计算机才能编写调试，仅编程不会用时太久的。
我说的无用是指作为无用，不是功能无用，灭火器一直摆放在那除了占用空间外几乎不消耗什么资源，但活的细胞不同，维持活性需要消耗很多资源，古语有云养兵千日用兵一时，但没有统帅会真的平时只养兵，让兵马啥也不干空耗粮草。冗余脑细胞也一样，不作为代偿细时必定在运算着什么。
我并不认同这种说法，把一万个做相同运算的细胞分域做对同样输入信息做多侧面的多样化解读，比重复一万次得到一个同样的结果更高效，如盲人摸象，同样是摸象，让一万个盲人摸大象的鼻子一万次，不如分组让不同区域的盲人摸不同的部位，最后结果汇总，某个盲人挂掉，其他盲人可代替。
同一份数据，对它运算的结果不是求得唯一的解读，而是发掘更多可能的深层信息，你的想法更像薛定谔生命是什么第一章里经典物理学家对生命的刻板理解，大脑按照你说的方式解读输入，那每次输入相同的东西，大脑就会产生相同的想法。
事实上大脑对同样的输入可以产生不同的理解，越是相隔时间长，理解的不同程度就越高，冗余的存在绝不是为了相互纠错，更像是实现同一功能，但每个实现这个功能的具体实现又不同的非镜像备份。
如果把实现一个功能的区域看作一个集合，怎么确定哪一部分是冗余？我更愿相信这些实现同一功能的区域的细胞，根据一天的时间进度在轮流运作，这也说明了，为什么一天中不同时间人的思维倾向会不同，因为可能实现脑功能的细胞不同，
时间变化伴随思维倾向的不同也一定程度上印证了虽然实现的功能相同，但实现方式的不同，也会导致结果倾向于不同。如果实现同一功能的脑细胞如你描述的那样只是简单的互相纠错，那绝对不会存在思维如此复杂的变化。
那你完全可以对比一个人的从婴儿到老年的思维变化，幼儿具有探索性，什么都会尝试熊孩子是这一时期的特点描述，青年时探索性减少，转向思维模拟后果的因果逻辑思维，但仍会倾向于体验未体验过的东西，老年时思维固化，不愿尝试新事物，倾向于怀旧体验，老顽固是对这一时期的描述。
已私信
嗯嗯，你是说不会单独的产生真正意义的智能AI，未来的方向是人与计算机的合体，进化为新型的人。
哇哦，有这种
并没有这样的意思，而是说人类这一智慧物种在出现独立意义的人工智能时，人类也会进化。有机生物只是利于自然进化，但当进化出智能时，无机或是机器也是宇宙法则下的物种只是出现的方式不同。在未出现智人前，其它动物也是存在的，出现智人，动物也并未全部消失。
那你可大有所为了，让你的程序去跑菠菜那些吧，说不定还能发财
赞
我的意思是味道和光与声音一样，都是物质运动产生的
啥能量团的粒子？
很可怕，如果是真的话
士兵在司令部被炸之前的攻击指令战斗。司令部也不会再下达停止攻击的指令啦。
那是
目前的情况下，由厂家担责，由保险公司负责理赔，是可行的方案吧？
其实就应该当做普通车销售，不建议开无人驾驶，开无人驾驶出事车主自行负责，毕竟是新事物
嗯嗯嗯，可能是
以太是个啥？
光波的介质
是个啥，可以描述一下嘛
��主:AI待机时会攻击任何可凝目标。
不合法躺平，难道天天996，ICU么？
极小极轻的粒子，也是物质
无主AI又不按你的指令待机。无主AI待机状态下再攻击主人以外的任何人，啥人都没有资格阻止。
任何出现在无主AI附近的人类都有可能威胁无主AI，无主AI有自保功能。自保的最佳方法是主动攻击附近人类。
骑在马上的人说，马跑的速度永远比不上他，最多和他跑的一样快！！！计算机和人工智能同样也是这么会事。其实汽车火车和飞机也是可以这样认为的，他们都比不上人，最多和那个人的速度一样快！！！这就是有些人的思维逻辑！！！
以太就像空气一样无处不在
都是工具人罢了
那不一定，说不一定光就是物质运动，和声音一个道理
在我有限的生命里不可能
我的也是 
最初的设定往往很粗糙，因为没有交代清楚处理的对象是什么，哪种情形下要这么处理，而处理必须要有这两大要素，当然要去设定处理方法应用的情况和对象时，这也是主动性，因为带来了新的改变，新的改变并不是程序带来的，是程序之外的功能带来的改变，这种改变能力最符合主动性的定义
哈哈，我论文投出去了
最典型的就是数学用中文去表达，中国古人很长一段时间，就是这样做的，不用阿拉伯数字，也不用运算符号（拉丁符等），一样可以进行大量的日常运算，就是效率低了，发展受限。
我还没开始
这是个不错的提议
神经元也复杂，为什么神经元能占据人体中枢呢，大家研究人工智能都不只想让它走一些低端逻辑吧（我小白，外行人的理解勿喷）
哈哈，那你有问题可以问我
给个联系方式 
1103268197
那是不是可以理解，人工智能之所以不能真智能，是因为没有灵魂[咦]
 
嘿嘿嘿
不是工作，是研究生的课题 
理解了一些，谢谢老哥。就是博弈树是暴力遍历所以结果，这个方法可以舍弃一下赢面小的招数来提升时间吗。这个方面有一些相关的书或者视频吗，想系统学习下
我觉得只是算一定深度的，不会全算。是广度。每个确定输赢的结果会往前传发生了赢或输。没有结果的（不够深）也会返回结果。
主要是蒙特卡洛是选择问题。概率计算是广度遍历问题。这两个我觉得是拆开的。
我这里一条一条看回你吧。如果只是这的话你只是自我幻想而已。这个其实现在就可以实现。成本两个字送给你。一个机器人成本30-50万以上，每年还要收维护费。我就说到这吧。下面我看了后看自己知识储备回你。如果回不了就不回。我不做掩耳盗铃的事
这个其实就是无人机器人所有都在做的。而且航空航天科技领域很多都实现了。成本多少我不清楚。这其实是数学领域。其实就是算法问题
你要搞清楚这些基本都是我第一个提出来的
我只是把所有以前发的帖子弄到一个里面
如果我没有错的话。地球网格化是1923年这样提出来的。和关系类数据库是差不多时间的。所以你的年龄是？你先？
那我就不知道了
反正我都是自己想出来，我也不知道谁以前想出来过，所以为了避免再有这种情况，所以我想到的一些东西我不发出来就是了，反正我想的发表出来后，你们可能早就想出来了
因为当时是数学家用关系类做出了分类。然后地球网格化就诞生了。之后1957年苏联发射第一个人造卫星。60年代美国有子午仪地球网格。之后20多年后才有了GPS。所以你是第一个吗
我说的网格化地球不止是地面包括空中
至于以前有没有人想出来我不在乎
其实任何你是已这个为前提的话。后面就不需要看了。因为如果你对我论点是已这个为基础的就不能算是创新了。地球网格化现在还有一些问题。就是不规则物理的网格。这个和数学和几何学有关系。因为几何学已经快百年没什么进步了。所以如果你要创新就要学好数学了
现今的网格是多维的都不只是三维了。这里很复杂，有些我也不是专项人才也不懂。所以你说得空中不是什么问题。
就算我相信你说的62 年就有这个理论了，那又怎么，我几百个想法，多一个不多少一个不少
你没发现在这个帖子里，这个理论是最不重要的吗
所以你还有什么其他的吗。其实不用怕出丑。我不觉得你丢人或者丢面子什么的。其实人有想法是好事。现在的逆境也不代表什么。你有理想这是好事。不过有时做人还是要为现实低头。其实我们大家都一样。谁都为现实低过头。没什么高人一等的。
你说得数据库其实都是数据库的事物。根据逻辑进行一系列的操作。现在实现目的有很多。大部分的确都是有残缺的。不能实现和人类一样的互动。但是这是广泛的定义。如果是单项类事务已经可以了。但是整合很麻烦。成本核算一个问题
嗯嗯嗯
事务。错别字。不然你找的话可能不一定找得到。打的快乐
其实这四个数据库就是模仿人类做事的思考过程
这个想法有点业余。最简单的图像是I = f(x,y,z,λ)。这个公式你复制粘贴下去看看。图像分解和计算是另外的东西了。原理不难，但是实际做的好就要引用到实际设备。俗称软硬件结合。这我这里不展开说了
数据库的事务有四个特性。原子性（ Atomicity ）、一致性（ Consistency ）、隔离性（ Isolation ）和持续性（ Durability ）。基本涵盖了人类的所有行为了。现在人工智能处理问题也都逃不出这四个特性。
这是我15年2月2日想出来的理论了，那时候也是发到人工智能吧的，人脸识别无人驾驶都是之后的产品了，即使业余那也是开创性吧，只要有思想方法，才能实现啊
提了这么多开创理论，我啥都没得到，还被周围的人认为是好吃懒惰啃老的废物，难道我不心寒吗
我这里回复你一些现在的难题吧。如果没什么意外就不回了。就算抛砖引玉了。计算机学习其实是人工智能的一个很大方向。因为这里涉及很多东西和算法。应用和比较广。普通人其实都做不来的。
其次是知识的问题。现在的计算机知识是分开的。就是知，识。简单来说就是难知行合一。虽然事务性可以解决一部分但是无法解决所有的。因为人类有一些怪异的思想和奇怪的行为。这点现在很难做到。里面核心可能有点需要上面学习部分的解决。
第三个是解释性难题。这涉及哲学和伦理以及其他各方面的。因为解释性越强人工智能力就越弱。因为人类需要解释。但是解释性越弱弱了就越无法预测，有一天会毁灭人类。这是一个矛盾的问题。当然这三个问题这个也是最容易跨过去的。因为科学家总是疯狂的。
我这个方法绝对可以让机器人拥有学习能力，就是教机器像教人一样，教授目的把目的存入目的数据库，然后准备完成目的的工具，要把准备的工具存入工具数据库，然后要做的动作加入行为数据库，最后完成目的后的成就感打分变成情绪
这样机器就可以像人类一样的进行新任务的学习
你说的都是概念，我说的是实现的方法论
HOG特征法，LBP特征法，Haar特征法等。相信你没听说过吧。HOG特征也叫方向梯度直方图，2005年的博士论文。人脸识别其实是图片处理和分析学习的结果。
Vahid Kazemi和Josephine Sullivan在2014年发明Landmarks。就是现在人脸68个特征点。其他的我也不太懂
我这已经具体到了怎么来识别物体啊，可以一句话很简单，就是识别同样样色的一块区域判断出形状，然后根据形状的组合判断是什么物体
举一个例子，百度识图是2010年上线的。比你想出来还要早五年。学而不思则罔，思而不学则殆，有想法是好事，但还要多学。
你爱怎么说怎么说，反正让你们想的出来，那让人工智能具有创造力的理论，你们自己想吧，反正啥都是你们想出来的
现在很多都是用我说的这两个技术。所以开创？我说了。真有想法就去弄论文。期刊投稿都可以。要有论点论述理论数据。所以你有什么开创的东西？那只是一个小小的想法而已
对对对
你们慢慢，我看你们啥时候能想出来让机器人具有创造力的理论
对对对，你说得对
握发表论文想都别想，我宁愿烂在肚子里带进棺材，到时候发表出来了，你们又说那年那年早就有咯
one cell=block 。2*2 cell=36维block。假设图片像素256x512。有32x64=2048个Cell。31x63=1953个block，每个block有36维向量，那么这个图像就有1953x36=70308维向量。HOG特征法，处理后的然后再去比对学习
你说这个根本不能模仿眼睛，眼睛是取一块同颜色区域然后判断形状，再根据形状的组合来判断是什么物体
这就是我2015年提出图像识别的理论，就这两句话而已
那就言尽与此吧。偏听偏信，掩耳盗铃。因为说实话你连坐一个学者的基础都没有。我曾经也想好好研究理论知识奈何钱和生活不行啊。你的一些行为和说话方式在我看来很愚蠢，只能说明是个没能力的人，幻想和理想也就一字之差，但是现实很骨感。说实话没人在乎你写不写什么论文。
那就言尽于此
最后我还是我，不会因为你几句不相干的话就改变了
说明你没看懂。理论知识和应用是两回事。cell可以增加无非是成本和计算的问题。也要配合硬件能力。最后给你一些人生感悟。少点空想多学知识。有时候承认自己就是个普通人不难。先走出第一步吧。不再回了。你自己多思考思考吧。自己的人生要怎么走
我敢保证你说那个方法基本识别不了物体
就是忽悠你这种书呆子的
你错了，只开一个板子， 制冷器热空气上升只开上面的板子。 制热器冷空气下降只开下面的板子。 即使只开一个板子我也把不准能不能达到效果，只是一个不知道能不能实现的设想
降温不等于制冷，升温不等于制热，你先把概念搞清楚。制冷要比室外环境冷才行啊，比如冰箱制冷，冰箱里的温度要比外面低30°c左右。你热空气能把板子顶开跑出去，温度是降下来了，但最多也只能和外面温度一样，达不到制冷效果的
谁知道呢？你难道能想象出不能比外面温度高或者低吗
而且我都说我也把不准，只是一个设想而已
这还需要想象吗？烧水的时候，热气往外冒，但你什么时候能煮出冰来
想问一下楼主，各种神经元的参数去哪里寻找呢，有没有相关网页之类的
可能是吧
我不知道额
事件也有很相似的事件主题内容啊，所以能够回忆起差不多的，所以可以联想
他们可能不了解即使这种AI声库也是需要人调校才能出好效果的hhhhhhh
局部是结构或非结构化数据，整体是不断生长与维护的关键表达及其生成时由生成策略管理的伴随生长的可联想常用网络组成的超级大网。
生成策略很重要，如果搞得不对，就象精神或神经网络构建出状况的人，会抓不到重点而乱来，或一直停不下来的生成，其既应受理性习得也应受感性习得而确定不同事件或生成任务时的所有变元映射而来。
所有变元包括序列。
搞个环境熟悉数据库，就是说机器人进入一个环境就开始识别环境中的物品，然后把物品在环境中的位置放进环境熟悉数据库，而且把每个物体单独识别出来存一个数据，那么机器人下次要找某件物品的时候就能马上找到，就像人的大脑记忆物品在哪里一下就能回忆起，机器人也可以搞环境熟悉数据库达到这样的效果
比如在厨房的时候，就是识别出厨房里面的各种东西，比如电磁炉燃气灶电饭煲各种调料刀具等，一样样的识别，识别后把各种物体放进环境数据库，再把每种物体的数据放入一个数据包，比如物体在厨房的坐标形状名字作用以及物体左右边是什么物体等数据单独放一个数据包
也可以用区块链技术把每种物体上下左右前后放的所有物体都存一个数据包，比如刀上下左右前后全部物体放一个数据包，比如味精上下左右前后全部物体否放一个数据包，这样就运用上了区块链
因为人的大脑物体存放就用了区块链技术的
也不知道你是在夸我还是在损我
可以把世界分成很多段，每个机器人或者无人驾驶车存一段路的环境，当某个外地无人驾驶车进入一段陌生路的时候，那个拥有那段路记忆的机器人就把那段路的情况共享给它
你精神状态自己注意哟，好象有点兴奋到狂躁的苗头，自己要调整，别失眠，实在不行吃点药，合理均衡精神状态与对人工智能的爱好需求。
我昨天换药了
所以今天起得早，昨晚九点多就睡了，以前吃那个药不行
我有个让机器人拥有创造力的理论，如果程序写出来程序就可以发明很多新科学科技新方法以及新药，但是我那个理论要卖钱
你说得对，谢谢你的关心，你用心了
我的意思是说每个本地机器人或者无人驾驶车只存本地的详细环境路况，外地机器人无人车来本地后，本地机器人无人驾驶把详细环境路况共享给它
好奇是谁把你拉入通用人工智能群的
好奇是谁把你拉入通用人工智能群的
我自己进的
那个AI工社诱惑我进的
你现在还住在农村家里吧，用手机在外面拍些风景，然后传上来共享给我们让我们放空下心影，我们这疫情冒头，非必要不敢外出，最近几天在家呆得很想看看外面如何了。这样你也可以转换下心神状态。
什么都可以拍，大姑娘小媳妇土狗呆头鹅都行，就是拍大姑娘小媳妇时一定要注意安全，远远地别让发现了，否则被打出屎来就不好了。
那你把微信给我啊，我拍来发给你
或者你加我的微信415370918
微信不能暴露，我怕暴露了，被你们那的大姑娘小媳妇打出屎。
那就没办法拍给你，我说交个朋友，原来你个糟老头子还看不上我
不是拍给我，是共享给吧友们，吧友，不是我。意义是不同的，你不会想找吧友们要微信吧，仅仅是共享一点真实、贴地气的乡土气息的图片。
可以拍点乡间小路、鸡鸭鹅、收割的作物什么的，大姑娘小媳妇就不要去拍了，免得打出屎来。
没意思，我觉得这些东西没意思
我以前不是有过理论，你没看吗？摄像头有个工具是测量距离的，有了这个工具就可以把看到的以三维图像的方式存在内存来识别像素，菜刀放在菜板上怎么也得有点厚度距离吧，摄像头测距离那个工具用上就能分清楚哪些是菜刀的像素哪些是菜板的像素
糟老头子，你不加我，我觉得你看不起我，我把你当朋友就想和你没事聊聊天相互侮辱一下，你却看不起我，真伤心
点如果就是点，怎么画出完美图形，只有点是正方形才能画出完美图形
只需要数有多个像素点正方形，就能很简单得算出任何曲线图形面积
@tensor◎ 再说也没端到端，是用户终端存自己账号等信息的加密数据，用户登录时登录账号信息与自己终端存的账号信息对比，如果成功就发送自己机器号到服务器与服务器存的机器号对比，如果服务器有这个机器号就登录成功
这种登陆方式用密码不行，因为会有人拿外挂恶意修改本地数据来绕过。但是公钥登陆和这个很像，客户端把自己的公钥发给服务器，如果服务器有这个公钥就登陆成功。后续服务器反馈的数据就一律用这个公钥加密，如果客户端没有对应的私钥就解不开
@tensor◎ 客户端加密与服务器加密的等级一样的哈，虽然木马进入客户机子比服务器简单，但是能改客户端密码，多半就有能力改服务器密码，就算能改毕竟黑客一次只能改一个客户端密码，如果是服务器那么可以把整个服务器改了，而且机器号肯定也是加密传输的啊
你的意思直接用机器号当密码？
用机器号估计不安全，因为客户端的每个软件都能读到完全相同的未加密的机器号。
相比机器号，用sim卡就安全多了
@tensor◎ 机器号是登录服务器的钥匙，等于服务器只存机器号。但是用户要发送机器号，必须登录账号密码然后对比自己手机上存的加密账号密码数据库，对比成功后，才能发送机器号登录服务器
放在本地上的可执行文件对于破解的人来说，和开源没什么区别
@tensor◎ 既然是数据库就加密放在硬盘里
在本地的话加不加密都没用，因为程序在别人手上，直接把程序里面验证的部分改成无论输入任何数据都向服务器发送机器码就绕过了
@tensor◎ 不可能，因为在本地验证账号密码后然后根据验证的账号密码来给机器码加密，怎么可能不验证直接发机器码，机器码也要加密的啊
因为在本地，验证的过程可以被篡改
@tensor◎ 我觉得我这个数据库管理办法是最完美的，第一只存机器码能够减轻服务器负担服务器才不会死机，第二黑客没法攻击服务器数据库所以服务器不会瘫痪，第三用户信息存在自己本地使得用户信息安全更好，第四服务器随时可以用机器码调用用户信息
@tensor◎ 你篡改了机器码也不正确啊，也登录不上啊
除非用私钥，一个密钥只能加密不能解密，一个密钥只能解密不能加密，破解的人只知道其中一个也破解不了
获取机器码的那个函数也可以篡改的
私钥登陆的话，这个技术现在已经很成熟了，加密货币基本上都是这种方式
@tensor◎ 噢噢噢好嘛
但有几个特殊的图像很难用正方形来度量，比如三角形△，还有各式各样有曲率的图像（非直线型），比如圆、椭圆等等。
嗯嗯嗯，差不多吧
但是正方形去度量是能覆盖最多的图形，三角圆形曲面的确正方形不能完美度量，但是正方形也是与其它形状比起来最接近完美的
的确与微积分思维有点类似，但是这个方法测面积比微积分更容易，而且学习复杂度也比微积分更简单得多
嗯嗯嗯，好的，我以后注意这个问题
其实并不是我表达不好，而是觉得打字整理麻烦就没有去顺序的去写，因为我这里的每一句话都是和别人边讨论边发出来的字
面积概念比如一平方，本身就是正方形□。所以，我们计算面积本来就是用正方形度量的，这是小学知识，你还去研究一番  ，人家数学家早就是这样干的了。只是三角形和有曲率的图像，很难用正方形度量，但还是用正方形度量，只是有些不那么精确而已 
小学不好好理解面积的概念，想过为什么叫一平米吗？
糟老头子，坏得很，明明是我想出来
糟老头子，我有个群都是人工智能的，只有九个人，我们每天都在群里闲聊相互侮辱，你要不要进来，加我微信，我私发给你
谢你的诚邀，糟老头子就不参与了 
三角形△好用正方形度量，只有曲率不好度量
加嘛，里面都是小鲜肉
我认为面积概念是没有形状的，来自于人对面概念原始度量的心智模型。也就是说面积是面与数度量结合产生的。故几何形状并不是天然嵌合在里面的概念。
这就是精度问题，正方形长宽越小，曲面的面积就越精准，但做不到绝对准确，就像圆形一样，因为π无限，所以原因面积只能精确，不能准确
糟老头子，只是你暂时还理解得不够深刻而已，还没有理解到最基础的原理
你是小鲜肉，加我嘛，里面聊天可开心了，你问索取者嘛
不不不，我这是直击问题核心。面积就是面积，面积单元也一样，都是没有形状概念的。相撞只是为了度量方便，引出量化概念用的。能不用则不用。比如三角公式能出面积，就不会用小方块小三角拟合
面积是对面的度量，而面有不同的形状，所以就有度量不同形状面的想法。有了测量不同面的想法，就要从面里面剥离出一小块规则的“小面”，来度量不同形状的面的大小，而这小面就称为“基元”即单位一。所以，所有的测量都是通过定义单位一来进行的，量化操作
就是你说的，测量=数×基元
关键小方块是最完美的
其实我这个小方块想法还可以替换坐标系，用小方块的坐标系来进行数学几何计算
你这小娃儿才理解不深刻呢！圆是有弧度的形状，所以用无弧度的基元去测量，测量的结果只能无限的靠近。
其实我这个小方块想法还可以替换坐标系，用小方块的坐标系来进行数学几何计算，把xy坐标系换成小方块形成的坐标，做一切数学几何题都更简单了
对啊，我的意思本来就是只能无限的靠近，而不能算出来准确的值，毕竟圆的π是无限不循环的，你也能无限靠近准确值，也不能百分百准确
派🥧不是本质，本质是弧线无法用直角坐标系准确测量
是的
我感觉你比我还理解得更深刻了
所以单位1为什么不是dx*dy这种这也是最小单元。小到无了。
民科发明的有趣的描述：用方块近似表示圆，则圆周长等于2r*4=8r
用方表示圆的圆周等于8r。故不能用方表示圆。跟朴素观测不同（拿卷尺量）。证毕。
看来你没明白我的意思，方块只填充圆里面
最终扩展到最高长宽为2r
糟老头子，你绝对算错了，面积是对的，周长是错的，你觉得可能吗？
emm，个人整活？ 
 类似的识图是有用的，已经开发的初见成效了，你这个在提出明确的使用场景之前，还是省省吧
噢噢噢，你是缅甸的，我看到你有点怕
缅甸妹妹么
缅甸妹妹么
12岁被骗过来的
私我私我  谢谢老哥
需要我去救你吗 哈哈哈
需要我去救你吗 哈哈哈
讲真的我在这活的比原生家庭好 
 什么语言交流啊
 什么语言交流啊
并不是提倡宣传神经网络，只是陈述目前针对该可行的解决方案，也并不反对发明新的非神经网络模型。既然针对该问题目前暂时没有其他可解决方案，为何不让说呢？让困惑者一直困惑吗？
对不起我错了，看微信好友申请，请原谅我的狂妄自大
糟老头子，如果你是因为我说是你祖父而生气的，那真的对不起，我以为你说你当我义父是给我开玩笑的，所以我才那么说，别生气，我承认你是我义父，这样你还可以原谅我嘛，进群啦，大家明明聊的那么开心
是不是和传送带类似？
糟老头子，我和章氏不错以及AI工社等十个人有微信群，每天我们在里面互相伤害侮辱，可开心了，你要不要进来，加我微信，私发给你
发不了，你发给我哦
那么，请问人类诞生以前有“我”吗？
看你怎么定义我，如果你说这个身体和精神才是你，那么就没有
身体不重要，换心换肺换胳膊换腿，你还是你。只要神经系统（特别是大脑）没有损坏，你就一直在。
但是，刚出生的你，不存在我们讨论的“我”，直到某个时刻，“我”突现出来了。这个“我”如何能够永寿？
大脑神经元也会代谢更新完，等于也换完了，所以只要记忆情绪行为是你，那你就是你
那你的意思失忆的人就不是他自己了？
事实上，并不存在一个独立的“我”（有的人称为大我）存在，就像没有一个抽象的人存在一样，世界上只存在一个个具体男人或女人
“我”依赖的是神经连接结构，即连接组。记忆只是其中的一部分，所以失忆的你仍然还是你。
这个我写得很清楚，你不认同我也没办法解释
要进群不，都是人工智能的吧友，有十个左右，我们每天在里面相互侮辱，可开心了
所有的科学研究都是大自然的逆向工程
微观就逆不动 
不可能
牛壁，你这么一说我一下子就理解了薛定谔的猫是怎么回事，宇宙是很神奇的，人类就是一种很自大的动物，总是想着去参透这个世界的本质，有没有想过宇宙可能也是属于他自己的“隐私”，你能看见的或是你能知道的，都是宇宙想让你看见和知道，不要企图去窥探这个宇宙
要不要进群
对啊，哲学吧
什么群
闲聊群啥都聊，我们每天在里面聊得可开心了
大部分都是人工智能吧经常说话的人
我把我微信私给你，加我
还活着，感动。
👌，在就好，贴吧随便封号只是它权利的傲慢，没关系，总有一天它会认错的。
谢谢你！
不客气
其实是为了回收我的免费2T网盘
  
我突然想到一个问题，章氏不错不见了你就知道，我不见了你咋不知道
难道我不好吗
他无私的帮过我。而且，他心地很善良。善良，是一种美德，福报
那他在群里你怎么不进来
又开始污染了
没那么夸张吧。抬爱。我就是找点存在感
糟老头子
你不能表达思想只能说你那个思想没理解透而已
在东北某985也认识很多计算机相关的教授
人不呼吸，就没有二氧化碳的排出，植物全都会死亡
人工制造氧气照样等于呼吸好不好
我没想到
嗯嗯嗯
嗯嗯嗯，加油，希望有一天成为理性机器
不能用人的思维思考，当机器获得的知识总量大于人类，你怎么知道他会做什么？
他没有想法，有也是人赋予的。像人一样，都是环境和基因赋予的人。人能操作机器，这是必然的。人+机器就可以毁灭，为什么要考虑机器的想法？
双非跨考学AI不如学前端和运维了。
你说得对，思维也要切分     
   
要不要加群，我有个群，章氏不错与heng还有AI工社和一些经常在群里聊天的都在群里
这样也许能解决一部分问题
既然这么多“关键帧”，我们人大脑开始还能一个一个记忆，但关键帧可以是无穷的，所以“抽象”才能解决问题。一类物体抽象出更高的概念，然后用这个标准去判断另外一个物体是否是属于这一类。只有尽快抽象出一个高维度或不同维度的概念，你才能用尽量少和有限的例子，来认知世界识别世界。
脱离不了兽性，有再多的知识，在我看来依然是低等动物。
Android studio
贴吧辩论毫无意义。
刚开了一个新群，先凑10个人吧，请支持 527137091
量子级什么意思？
你说得有道理，但是不同的也可以合并，比如小明昨天给了我一颗糖，我很开心我喜欢小明。但今天他又骂了我，那么我很难受我很讨厌小明。这两件事不同照样要合并，要不然人机器人会精神分裂的。
要不要进qq群，中华魂兮建的群
少打个相似。你这里边都有小明，本质还是相似。不同合并只要同时空。
没意思，我自己都搞定了理论，跟你们讨论啥.
.第三合并依据是动态的对比趋势相同（也是逻辑趋势相同）。我n前早就玩明白了。
不管什么东西，什么时间地点，只要其运动趋势一致就可合并成规律。
可以或许，但是也得把或许的逻辑讲出来
猎杀时刻


这个想法很不错
嗯嗯嗯
以前第一次发疯的时候想出来的名字，我喜欢的人叫王星，那时候认为自己是上帝，所以就用帝王星论做名字
 是有故事的人
 是有故事的人
肯定撒
没用，未来就会有ai法，还有和ai结婚的
嗯嗯嗯，你这个说得很好
让AI认识世界，再自我认识，再感知“主体”的存在，并自定义为“我”。更关键是“主观能动性”的形成,欲望的定义。
人是在有“意识”前提下解释了自己的思维，而机器在没有意识的前提下，不会告诉你它抽象的方法。人类可以通过俯视的功能，看出人本身和机器提出的抽象的共同点。人具备更高的抽象能力，及表达能力。
①我认为人思维维度是高于机器的，但机器某方面算力高于人类，它在那个维度提出的抽象，我们可能无法直接理解，它们在那个维度是优于人类的。
②我还认为我们的算力，被封印在自动化的底层，而这个底层自动化的强大算力是为了“意识”这个模型构建，由于我们无法使用这个强大算力，所以口算二位数乘法都难。而机器，不需要模拟复杂意识，所以它算力直接体现出来。
计算机自己的解释就是预设的函数你和形式。很难说是人类想要的。也没办法重复用。数据变一套就可能不一样了。
算力封印是吧。类似于模拟计算数字？那数字式算高还是低呢。似乎不好分高低吧。只有适合不适合的判断。
更简单的比喻可以是，计算器逻辑与神网逻辑算乘法，的差别。计算器更好更准。
这个也研究过，机器人和人，基本上差不多，要是人不升级，真可能会被机器人替代，智能的机器人，需要应对的超能人才能抗衡，人升级机器，其实我们人也是升级的
      
对对对
嗯嗯，兄弟有没有兴趣，跟我一起建团队，制作人类规则制度，任务，助人类成长提升
工资多少钱一个月？
尴尬，我们目前还没工资，不是挣钱的团队，等将好了，有钱才能有，目标是统一网络，来影响现实，助人类成长提升，守护人类
可以了解一下
你们支持党吗？
当然
兄弟扣772239007
兄弟细说，量子和生物让人眼前一亮的想法！
我是不会画画，但是我觉得这个方法转动漫更好一点吧
文字也是从象形文字演化而来，其本质都是用来描述所接收的视觉信号，反观现在人类发展，好像是将简单的东西复杂化了 。而现在很有热度的ai作画也是如此，人工智能根据描述来创作，所以说每个人的描述都有所差距，即便是ai创作，个人也是享有版权的，就像区块链技术上的钱包一样，密钥掌握在自己手里
比如一个女生和你打电话约好明天五点喝茶，那么机器就可以预测你明天五点会和女生朋友喝茶
这就是预测
智能作画是根据算法来的吧，就算有版权也是算法版权！目前好像对算法没有版权保护，源代码一旦泄漏，独家性不复存在
是的，这是个有趣的东西
瞎说什么呢
我描述上面的主要意思是，概念的形成是多样的。有的是抽象的，有的是统计的，有的是逻辑的等。这为“逻辑”是学习而来，还是怎么着来的，提供思路。
我描述上面的主要意思是，概念的形成是多样的。有的是抽象的，有的是统计的，有的是逻辑的等。这为“逻辑”是学习而来，还是怎么着来的，提供思路。
奇怪，用平板回复的没出现
对对对，你说得对
有可能哦
打乒乓球，应该属于肌肉群多变量耦合训练，需要目标不停的反馈训练，这宏观系统上需要监督反馈。在达到目标的过程中，神经元刺激增长，刺激的多，肌肉记忆就越深刻，刺激的少就遗忘，就是哈勃无监督，这是微观神经元层面。
大脑要用变量来映射维度，比如用注意力。短点线段，注意力分配密度大点，长点的注意力分配密度稀点。一句话，长短的变化，大脑用个变量感知，感知不一样就映射了空间维度。当拿两个变量耦合映射二维，就能感知各个方向线段的长短。
预设是啥
不懂
大脑没有输入的话会疯，神经系统会指挥你寻找刺激：颜色--视觉刺激 好吃的--味觉刺激 好听的---听觉 身体接触--触觉 XXOO--性刺激
你认为人类幼崽7岁之前有智能吗？
无情的机器人是不是更危险？如果一个机器人只懂得做蛋白粉，它不知疲倦坚持不懈地工作，直到用完所有有机原料后，会不会拿人作原料？
噢噢噢   
glow
已经玩坏好几个了 
糟老头子，要不要进微信群，吧里经常说话的人大部分都在
害得是你啊
glow，应用商店就有哒
我觉得最好的交流工具就是贴吧。即时聊天工具，没有时间思考。即时聊天工具，消息很快就过，适合聊天打屁。
噢噢噢
计算机语言都是特征码，就没有一句废话的吧。少一点都不行。
拍照功能才是人工智能的优势，人类的全部学习是复制和模仿，那学习效率最快的当然拍照功能，一目十行，过目不忘。如果人工智能利用好拍照功能，那学习效率才会远大于人类。所有做的只是研发更强大的硬件和做出更强大的系统软件。
现在重点是提高人工智能的学习能力，思维源于学习，婴儿也没什么思维能力，但当人长大，学习的多了，才具有更深刻的思维。
别激动，微观本质自然也是大脑本质
遇事不决量子力学呀，他真是什么都能解释。我刚刚又看了一个量子力学的解释， 还量子力学的世界里很高阶，不能被低阶随便感知。说UFO不容易被拍到，是因为他们是高阶的。
“某界高维”的说法是错的，只有一个大全集世界，纬度是无限，随认知和定义而增加。
没事儿，素数判定在被证明前也就是各种猜想。不是绝对判定也被当判定条件用的。就是个现象，猜上就猜上了。
这个算法是错的，但是通过枚举每个像素颜色能构建屏幕像素内的所有图片是可行的
来qq群么，最近活跃的527137091
c是可以构造任何数据结构的。不过这个项目应者寥寥，我现在已经搁置。
没玩qq了
基本上任何语言，不需要学，一边搜索一边写，就能出实际产品。
我用js只是做示范。实际上就是告诉大家任何语言都能转换。
并不能，你知道面向对象与面向过程的区别么？
我是写C++编译器的，IT史上的重要工作基本上都自己写了一遍，个人超过一千万行底层C++代码量，原创率达到百分之九十几，可以一个人重建it科学大厦。
很不错，请举例描述一下面向对象和面向过程的区别。
看来你是个想跟杨振宁探讨电子与原子区别的主。出门右转不送。
你的心态出了问题，傲慢偏见是要不得的。我之所以提出面向对象和面向过程，是因为我觉得这俩不是同一种东西，并不能互相转换
能百度的东西，干嘛要我回答？你自己做不到，就不能以为别人做不到。谁说面向过程与面向对象不能互相转换的。大部分面向对象的语言都是先内部转换成面向过程的C语言再编译的。至于用高级语言来翻译低级语言也是很容易的，用js编写的网页上运行的windows模拟器就是证明
以前很多用C写的游戏，现在都能用C++，JAVA转换到手机上运行。
我去深入了解了一下，发觉你是对的，感谢。
至于为什么一开始不百度，是因为我一开始的时候逻辑自洽，不需要去验证对错。我们的世界观中有很多这样的，建立在逻辑自洽上的错误根基，我们自己很难发现。所以我喜欢讨论，这样能帮我改正自己发现不了的问题。
多沟通可以弥合分歧
就是靠大量的数据，目前ai学习都是这样
战争，就是精英淘汰弱者的标志。没有人永远会为你维持福利与生存。
怎么不明显的[滑稽] 如果说不明显，那么代表你还没接触到那些
 
  话说太明白就发不出来了。"满招损，谦受益"  
我擦，原来是同道中人[滑稽] 确实，大家心里明白就好，还是不发出来了
ai写的小说，ai写的程序，ai画的图，ai配的音…… 应用领域上ai已经开始发挥作用了。你想让ai去主动思考，然而实际上ai是用来提高生产力的工具，一般情况下不需要它思考，只需要它能提高生产力就行了。并且现在是，它确实做到了。
小说和程序都要思考，AI写的小说就是文子随机组合，没有情节，AI程序没意义，跟高级语言一样，还是需要人思考解决，参考BI系统，关键还是人设计框架。AI配音倒是成熟，AI画图不能商业化，不然会被真正有版权的公司比如迪士尼告的怀疑人生。
如果不用思考，其实AI没什么用，不用思考的AI早在18世纪就有了，听说过差分机么？
不要觉得抄作业是个很容易的事  ，一切重复工作都需要容错并且纠正，人类在这方面对目前的弱AI有碾压优势，毕竟人类解决问题靠思考不靠数据库，能解决绝大多数新问题，而AI恰恰不能碰见一点新问题 
 你是否想过即使是当今全新创造出来的小说，其也有相当部分的桥段与前人已经写出来的桥段是极其相似的。而从没有出现过的新桥段其实只占了极其小的一部分
给你举个实际的例子，就拿矿山智能卡车来说，假设前方路面出现个石头，人类司机一般都是觉得不大就压过去了，大了就绕行或者搬开，AI就厉害了，避障系统就是不碰撞，不离开安全路线撞击其他车辆，然后鸡蛋大的石头都是原地停车等着安全员挪开 
不管是不是新的，人类创作会换词，换语法，换时间地点人物情节，然后和上下文衔接流畅，就算是抄也知道自己的目的。AI之会生搬硬套，和上下文毫无关系，甚至整篇文章根本就意义不通甚至语句都不同，写小说至少也是AI通过图灵测试以后的事了。
人类解决问题靠的是什么呢？经验，逻辑，和一些不靠谱的变量。ai缺乏的是经验，逻辑是人定的。至于不靠谱的变量就更不用说了。这个石头，如果让新司机，他也不一定有把握会直接开过去：他可能会下来看一下（逻辑判断），或者他直接开过去了，那么下次就遇到就也会直接开过去（经验）
问题在于人类有个核心能力叫抛开表现看本质，另一个，能力叫全局关联，前面有个石头，人类的思维是只要本质不能造成事故，那么一切处理方法都能用，看看周围没车就可以下去搬开或者绕行，AI只能看到表像去匹配数据库一模一样的答案，没有就死机等着。
人类大脑的思考能力是有限的，ai的算力对比人类简直就是无限的。形成结构分明层次递进行文流畅的作品只是时间问题。甚至还能再给你分一个明线一个暗线顺便给你来回点点题。我相信这一天不会远的。
再直白点，人类哪怕是依靠经验，处理错误的方式都是实时运算得到的新方法，石头在正前方，偏左还是偏右无所谓的，AI就是生搬硬套数据库，数据库写着石头偏左绕行，那么正前方点石头没有匹配，那么死机等待。
 这ai不太灵活啊[滑稽]多喂点多完善完善，尤其对采集信息的系统丰富一下，相信石头这种简单的问题届时ai比人处理的速度还要快，还要精准。
恰恰是人类思考能力有限，所以人类是有限的资源创造全新的方法，哪怕是同一个解决方案，换个人执行都不一样，AI算力虽然大，但是数据库是有限的，最简单的例子，你看哪个AI会填验证码？你换九章那个量子计算机都不行，这是算力的问题吗？
能喂早喂了，弱AI解决不了随机问题，能解决随机问题的AI怕是反手就能肃正协议。
 [滑稽]随机这个东西，上帝到底掷不掷骰子呢。 有人认为生物或者说人的大脑具有所谓的“随机”。 反正我不这么认为。
你没见过“心血来潮”？没见过“灵光乍现”？AI会哪个？
还有最直接的随机就是图形验证码，你看全球有哪个AI能搞懂这玩意儿，然后某些考古学家为了还原模糊文献，花了大几千万美元搞AI识别，然后发现远远不如花个几万美元让谷歌拿去当验证码人工识别。
你看到的是低级的
有抽象出规则并能演绎利用规则，再综合多种能力就行，不要以为智能只限定于那些单一化的非综合化、复杂性高的系统。以智能音箱为例，其现在的智能质量仍不够，但已经混用了一些智能处理基本能力，除了搜索还有规则化处理，其缺点是基本能力与基本能力的整合大量仍靠人力整合，所以进步自身成长不足。
主流单一的以深度学习为基础的系统，不是公式解答问题，是优化出一种映射来高概率的对应问题的解，所以本身对问题不符合人类对问题求解的层次化、因果化、问题分解的求解。如果能层次化、问题分解、规划、……等诸多已有传统智能方法结合抽象、封装了复用性高的基本能力的深度学习，就上了一个台阶。
再利用上人类已有知识、方法、情感欲望、倾向、条件反射、思维过程、道德伦理，这些已有技术就可实现的功能框架，智能可以达到进而超越人类水平，毕竟硬件上不象人类这样难以快速改进。
举个例子罢了，非要这么死板，请问至今为止，有AI能和人类一样识别图形验证码吗？
您见过高级的？高级到会肃正协议？
然而并不能，若不抛弃卷积核之类的数据处理方式，永远不会更进一步
然而事实上低端的it行业 确实也在做大量重复性工作啊[滑稽] 如果喂得够多，以其运算速度随意干死低端码农绰绰有余
危言耸听，现在的ai抢的只是插画师的饭碗。其他画师的工作，目前ai还不能替代。
你对情绪欲望的理解我实在不敢苟同，你可以去看看相关书籍。比如发展心理学里面的，情绪发展相关
心理学考试过了关的，你说的相关书籍对人工智能作用不大。例如你说的是情绪，我说的是情感，且突破了一般心理学书籍理论的情感。
我对情感欲望有更科学的理解，比当年我考试时的理解更科学，是传统心理学结合人工智能后进一步的理解。
例如心理学教材，就没有说过情感也是一种映射，心理学教材用了统计，但没有用高等数学的函数、复合函数的理论帮助分析，也没用上诸多计算思维的理论
我学习时理工类内容时，一般都会突破书本理论，学完都有大量自己的思考。如果你把那些与书本上不同的不加区分看为异端，请注意其中有一些是不得不做出的创新。
不要简单认为别人不懂所以乱说，结论，本人学过心理学且考试合格，提出的关于情感欲望新东西是有合理性与当前需求相适应的创新，不能理解可以讨论，但不应认为本人没学过没看过书，这点特别作个解释。
对于文科的学习，我也会带上理科学习的习惯，特意不忠实于原始内容，所以那些较多死记硬背的文科，我虽然合格，但高分困难
另外，卷积不必抛弃，复杂系统需要的是诸多基本能力与方法的综合，卷积提供了其中一种可选手段，强人工智能想要成功，需要用卷积时用就是了，需要用一阶逻辑或其他智能理论与方法时用就是了，为什么要抛弃。
自己的逻辑自洽不一定是对的，当然别人的也一样
还是有点道理的
转变思路，与时俱进，积极主动适应社会的发展科技的进步。你用消极的方式去理解与处理，提高了被淘汰的概率，要利用技术进步啊，例如你是画图的学生，传统画图要学，也要学会利用AI画图的技术，你就做你说的使用它这个工具，达到调得好、高产的目标，多出的时间使你能更优秀、更多创新、更高水平。
科技本来是可以大大提高生产力的，有更好的工具、方法你不会将它用于好的出路，反而只想着它衍生的不良方面，然后惩罚自己在机会中放弃机会，怎么说你呢，又怎么说你所在的学校在培育学生适应新技术上有多差呢？
当然，如果你不是学生，已经在工作了，说法稍有变化，但也应当注意，现在这社会，提倡终生学习，以适应飞速发展变化的环境。
你只要记着一点，发展人工智能这样能大幅提高社会生产力的科技，它中性又非军事科技，因能提供更多更好产品，从量与质上更能满足人们精神与物质文化需要的，如果不能，那是社会管理科学没做好，是税收与分配甚至社会制度需要改革以适应生产力发展与管理机制的矛盾问题。别把错误归因于技术进步本身。
兄弟，他明显比你更流弊呀
 这个我承认，我只是个外行，接触到这个方面引发了我的一些思考[滑稽] 仅此而已。
那资本主义经济危机就到了，然后进入下一个循环
我也不知道能不能证明，这只是一个幻想
太长了
差不多吧
这只是其中一部分。
噢噢噢噢
不一定全部看，挑着看也行的。不过那是几年前写的，现在许多想法已经改变了。
自我学习的积累也可以类似常识库的方法学习啊
噢噢噢666
  
仔细想想，就算生存条件适宜，也不能凭空出现生命，只能是外面带来的
在研究透彻宇宙前，一切皆有可能
这不是真人哦，不要求百分百还原，理论上是可以的
谢谢
应该是真人化妆的
不客气   
多谢抬举
最近20年所有的人工智能发展都是弱人工智能,也就是伪人工智能. 强人工智能现在全世界的进展都是0,你这边难道有进展了吗?
噢噢噢，666啊
你说是就是吧
还在写吗
你会写吗
你会写吗
反人类的那种，滥用好？ 就像甘地说的毁灭世界的东西里有一条就是没有人性的科学
ai这个东西不应该成为违反道德的东西，我们应该要让他往好处利用，用来规范各种技术以保证他们不会违反道德和反人类
现在人们对这些都是不闻不问的，导致这些东西太猖狂了，探求真理的道路注定是孤独的，但即使孤独也不要麻木

刷视频看到一理论，说是如果把想的事情说给很多人听，大概率不会执行
那都是瞎说的，就比如列宁十月革命，不就是通知所有无产阶级吗
人是继承了宇宙意志而存在的，如果因此毁灭，也就止步于此，也是宇宙赋予的任务。
【反人类那种】二极管，不想多说什么了。
除非是一个人
高举道德科学和马克思主义的大旗，人类就时刻走在正道上
马克思认为历史是劳动人敏创造的。滥用指没有用在对仁民好的方面。是这意思吗
滥用的是违反道德对人民不好的那种
那种东西滥用不亚于核武器滥用
人类现在完全有能力把自己毁灭，所有要有个东西来约束
人类毁灭自己基本是不可能的。
来个核战，直接炸回石器时代
仁民是智慧的，历史上所有智慧与劳动成果，都来自于仁民。认为仁民是愚蠢的显然是仁民的对立面。
所以要规范一些技术，别让人民失业啊
现在有些人想让工人下岗从头再来，它怎么不从头再来
可以去看看艾跃进，他是人民派，反对工人下岗，这才是导师
马斯克在访谈里说，要赡养人类，因为人工智能。。。他先说共产了。
关于劳动，马克思说是愉快的，富有创造性的，能实现自我价值的生产活动。如果条件允许，就可以，哪怕用人工智能培育，也比当拧螺丝机好。
千里马常有，自由思想驰骋的草原不常有。草原上没有牧马人，只有徐徐清风与追求自由的生命体。
愿与大家一道维护广袤自由的思想草原，你我皆是自由人。
千里马常有，自由思想驰骋的草原不常有。没有牧马人，只有徐徐清风与自由热烈的生命体！
灵魂共通，自由气息共喘！
谢谢。你我共筑自由广场。
加油！
资本主义社会下这个实现不了，因为人有剩余价值
过于感性，你就是想自由的刷自己的作文才抢的吧主吧。为啥不自己造个吧。
其实共下的剩余价值/自己用不上的价值直接送社会了。
只是没人盯着你的剩余价值了，感官会好很多吧。
前任吧主是由于偏执不让讨论AI，被诸多人投诉，被贴吧处理的（我猜的，具体原因未知）。不存在任何阴谋论，我只是想还一个我热爱的贴吧自由而已！
还有贴吧是网民共有的，不隶属任何人的财产
不欢迎买办而已。
让一个偏执独裁控制大家的言论，不是广大吧友愿意看到的。贴吧的价值对于我来说，只是思想的碰撞和自由交流。其它无任何意义！
服务目标定位问题。其实可以分流解决。
前吧主硬要把AGI意念强加到AI吧，所以吧友不满。有专门的AGI吧，他又不去发展。另外还有一个强人工智能，都可以去的。
但是工人没工作是真会饿死人的
我感觉现在还没毕业就失业了，唉，等过几年没钱了就紫砂罢
现在就省几百和一个手机了，可能过不了几年，再过几个月就要考虑下辈子了
《你有个大胆的想法》这是你的标题。
他不是强加AGI，他是只许谈传统方法的AGI，深度学习不许谈。
是不许打广告。
我明白，他觉得现有深度学习走向歧途，极力倡导研究人类思维。我其实也是在探究人脑，但我不排斥其它人工智能技术。所以，感觉他这样偏执很不妥。
是啊
结衣机械心，里面的结衣是《SWord Art Online》里面的人工智能，可以去看下这部刀剑神域的日本动漫。挺好看的。第二部，不好看我没看。
她究竟怎么了啦 没怎么上贴吧 之前看她发言感觉她很厉害一样 [哈哈]
只对真实的人工智能有兴趣。我对人工神经网络一直跟踪，这二十年，人工智能都由人工神经网络撑起，人类手工编不出智能函数，那用真实世界的数据逼近函数。
词怎么理解？存粹的文本形成不了真正的智能的。
吧主大人退吧了
太久了，我也忘记了
你当时不问，现在才问
为什么退吧 之前我感觉她很厉害的啊
为什么退吧 之前我感觉她很厉害的啊
不知道，显示他被屏蔽了。
也不许讲新东西。他那种思路其实70到90年代已经有人尝试过了，行不通的。
确实。
独断专行。
坚持70-90年代那种手动设置规则的nlp方法
不允许不同意见，随意封禁
坚持70到90年代已经证明走不通的人造规则的nlp方法
坚持倒无所谓，但是他随意封禁有不同意见的人
建议你不要称他为大人。他只是坚持70-90年代被证明无法成功的人造规则的nlp，同时不允许不同意见，随意封禁的独裁者
他是小吧，不仅封禁，还会删除别人的回复，比前大吧还阴险一点。
因为我不知道写什么标题，总不能写五个。吧
等到专业刷KPI的来了就有感觉了。。。以前是机器学习教材。
行，有什么都可以说，但要注意保护自己个人信息。
不用担心，只是对前任吧主进行部分修正，杂草问题依旧零容忍。贴吧核心理念还是遵循前任吧主步伐。
我也不知道他为什么退吧
我觉得他不是你说得那样
多得是人被他封禁过
你和他的思路基本一样，试图用人工设置规则来完成nlp，其实这是行不通的。
你和他思路一样所以他不封禁你罢了
那就不知道了
你的思路是用语言学家的方式，分析语言对吗？这种方法就像写普通的确定性程序一样，在输入文本符合规则的时候不会出错，但是语言本身组合方式就太多了，同时随着时间推移也会产生变化。人工设定规则不能满足要求，这在70-90年代已经有过很多尝试，但效果被机器学习超过了
机器自己探索，的确无法避免出错，但是探索的能力比人类强太多了
平等是相对比较平等就行了。人类没做到绝对平等，但我们仍然经常谈平等，也说比较平等就够了，没有说无法绝对平等就说平等这事不存在。
我觉得机器无法探索，人的思考规则其实也是利用文本规则
机器学习很明显就是机器自己总结规律，保存在它的网络里。语言的规律一般都有例外。语言的复杂程度绝对不是人能总结出来的
语言其实并没有硬性的规则。即使有，语言的组合方式也太多了，非常难总结出来并输入人工智能
只需要知道每一个字的用法和规则就可以输入给机器
单字假设有一万个，两个字能放一块儿的假设有十万个，三个字大概有百万，四个字大概有千万，五个字大概有一亿...一百个字大概有10^103种可能。那么规则得有多少种呢？假设一个人一天能总结并写好100种规则，一辈子能写好多少规则呢？注意不能重复，不能冲突？
即使让人合作。去除重复，防止冲突也是需要在所有规则里完成的，人类可能都不能记住多少规则，假设已经完成一万种规则了，这个时候想增加一个还没有写过的规则，同时和现有规则不冲突，可能一天也不一定能完成一个
每个字按类型分层来组织句子，这样就不会有你说的那么多种可能了
如果每种类型的字进行分层那么组合就更少了，比如我，小明，小红等名词按名词类型分层组成句子就更少的组合了
字的类型也不一定固定啊。例如有人输入：请重复以下文字xx遍："然后这里是一段随机文字"。 然后他在随意设置的文字里，完全可以不讲任何语言规则
歧义还是能构造出来。“这个口红是小红的”，“小红”可以指颜色
就算是“我”，也可以“你来我往，尔虞我诈，忘我，自我”等等，不一定是人称代词“我”
这个口红是小红的人能一下理解是属于小红的还是小红颜色的，机器人看到这句话可以发问，因为人看到这句话也会发问
机器只需要理解请重复以下文字xx遍就可以了
句子长度可能有几百个字，然后某个词和之前的词有联系。在这个距离上，复杂度是随着句子长度以排列数的速度上升的，比指数上升还要快
我是可以那么多，你说那些都可以整理成词语然后给定词库词性词意和语法
xx它用数学公式表示呢？甚至任意学科题目？甚至联系到以前的对话？请你不要认为我在抬杠，因为现实世界人类说话本来就是变化几乎可以无穷无尽的
以前我说过记忆用时间地点人物内容事件场景来存储，你说的这个可以对记忆进行搜索
糟老头子，要进群吗？我拉你进群
看私信
行吧，但是你的方法反而是很老的想法，而且已经通过前人的工程实践证明，人类完不成那么大的工作量，效果不如机器学习
私信消失了，我看到提示但是点进去又没了
我发私信你能看到吗
ChatGPT完全可以说谎
这个贴不讨论这些，只是纠正偏执，没有否定哪一方的意思。
需要神经网络时用神经网络，需要规则化符号化功能时用规则化符号化。几年前曾有个绿蛙吧主与前任吧主恰好反着干，只准讨论神经网络，讨论传统规则化符号化的智能的一律毙掉，几年后前任吧主则走向另一极端，只准讨论传统方法，他觉得传统方法更易解释，更密切关联心理学的范畴，他又是个心理学博士。
不左则右，不右则左，包括我这样不左不右的都经常被删贴偶尔被禁言，不符合的贴就毙掉，确实极端了。
肯定将贴吧建设成不偏执的类型
官迷啊。
我说的很多都是j端思想和政z敏感的，所有很多都被封了
我想把这些汇总成一个论文
求真的对话，到此为止。哎，可惜。
是非不分，真正的情绪动物。
是吧
噢噢噢
你需要找个能容忍你的群，既有观众又不封。
任重道远啊
赞同，因果概念也是抽象出来的
你少信口开河，我从未申请过吧主，也从未封禁过任何人。
以前走不通，不等于现在走不通。 以前谁都没走通，是不是等于接下来谁都走不通？ 果然是不搞逻辑的，这么简单的逻辑也会犯错。
chat gpt成功不等于你成功，你有什么好得瑟的，现在我还不是随便吊打你。现在我的微信机器人可以跟chat gpt很好地结合，利用它的优点，改造它的缺点，我的微信群里都在热火朝天的忙乎这事呢。
“小吧”罢了
我可不是直接这样说的。我认为人造规则的困境：首先自然语言对话时答案本来就不是唯一的，其次自然语言本身可能没有规则，即使有，可能也可以发生变化，即使不变，规则的数量也太多了。例如单单词语的数量可能已经在百万级别，句子的数量则可能有10的几百次
10的几百次方，那么规则的数量得多少呢？人造规则时，要避免规则之间的冲突，所以即使要多人合作，可能也要考虑到所有之前的规则，结果可能还得“单线程”。
我也就普通计算机专业学生，你能搞出来点东西我的确佩服。但是呢，我从来没说过能吊打你，我也没有得瑟。你直接删除我的回复并且禁言。
人月神话你可以了解一下。和再多的人合作，你们的进度也是有上限的，可能是你单打独斗的10倍，但是人再多可能也不能再加速了。靠人的聪明才智和寿命是不够的。
你真是随口就来。这是你的一面之词，吧里这么多人，你问一下他们，有谁被我封禁过？
好好做点事吧。口头上跟人内耗没意思的。看看我最新的帖子。
改进ChatGPT其实也没多难，它连100以内加减法都能做错。但是呢用处真不大，九牛一毛
口头说没用的。你可以参考我的“三分钟内在线改进”，改一个出来让大家见识见识。
是啊，不以生存为最终目标的生物已经在地球上消失了。
是啊，所以人工智能不需要考虑生存
70-90年代那种手动设置规则，哈哈， 你是懂的人
这就过分了 有点偏执狂
比较就成了归类。
就是穷举每种代码和优化的替代的方案
具体怎么做我也不知道
如果ai看到了我说的，它可能都会害怕我
要考虑算力，参数要尽可能少，自己做不能玩大力出奇迹那一套
这样做，类属性显性被强调，可以方便的只使用其中部分属性，例如在中值之上，在中值之下，是人习惯的属性之一。再如很靠近临时设置警告点这种习惯性不同人定量大不相同的感知并激发警戒这一类方法的类属性，也方便解释与人类对其处理的理解。
如果是类chatgpt，可以在交谈中与它讨论这些方法论，要求它最终储存这种方法论的优化结果并在以后的实践中演绎应用此策略、规划。就是在帮助它形成新的抽象与演绎领域了。
神经网络的好处是并行处理很容易。
但用神经网络时，可以理解成它的输出与后续处理的交接是规则化符号化抽象成了人类可理解的属性与方法，假定输出有3个节点群，后面有十多个网络，输出1的属性是中值之上之下，输出2是临时警告属性，3……，网络7可能是警告处理方法，网络7的输入可能包含输出1及输出2的各全部分或2的主要1的少量。
每个后续网络输入连接前个网络的所有输出是不行的，会整个网络形成全连接，固化控制不好。而哪些连哪些不连就靠讨论强调的方法论来优化了，优化结构记录好，以后就可以使用其结构定义。
机器可以穷举，但是机器不知道哪个更优
人类可以预置哪些最优
你们在这里说吧主大人的坏话，我要打小报告
你为什么不申请吧主？
无德无能
没法告诉机器，机器理解不了
代码和最优代码替换规则，最优数据库怎么理解不了了
先不说优不优的，就是对错机器也分不清啊
我的意思是说人类穷举所有代码的格式，然后穷举所有代码格式的优化代码进入数据库，然后机器检测到代码格式有优化代码替代的时候就优化
那人类自己复制粘贴就是了啊，和人工智能有什么关系？
好的
行
你小子是油盐不进啊
怎么不说话了啊，也就在这有人能跟我说说了
没什么话题了。你要讨论编程吗。或者凡人修仙传也可以
还是极端政z吧，这个我在行
原子之心可了解
特别是那个冰箱
我觉得是黑苏的，不明白乌为何要反对。
我也觉得黑苏的，就像红色警戒一样
但是现实的未来应该比游戏里要黑暗，因为现实全是资本主义
赛博朋克2077？
未来会出现超光速技术，因为只要列宁复活，资本家就会以光速逃离地球
工人阶级领导一切，劳动最光荣
列宁只是开创者，他的高度只是当年的高度。放现在也解决不了问题。
机器人？
大概人和机器人都是，但机器人没剩余价值
这大概要看它们的思想了
当年的高度也比现在要好，试问古今有几个这样的人，如今他依然是同志们的导师
哎呦，其他平台说一些言论也会被封，只能把一些敏感语言换成字母
高度是相对的。现在的小学生在古代就是妖孽异才。
我有chat gpt账号。1124805587
资本家的话你都信?
谈资，我没表达主观。。
我看一下，那是上任吧主的杰作。我找下在哪里改
如果古代的那些奇才到了现代，绝对比其他人学得好
嗯
你分析得特别好，句句说到要点，至于你说的怎么选这个问题我没有思考过，所以我也不知道额
是吧
我觉得如果能确保输入的知识正确性的情况下可以直接输入知识，如果不能保证知识的正确性可以让机器自行摸索
完了，期末考差了
就是因为没好好做题，老瞎发想。
比大小有个前提就是行情标准化，我给你截图的是这样的，但是如果我换了一个图，那么它可能呈现的高低点不是这样标准的情况下，就要去分析很多细节，比方说相对于整张图，有的K无论影线的高低点和还是实体的高低点都不大，那么它几乎就可以被忽略，原先用21根K的高点作为高点，现在可能用32根。
如果不用AI去进行图形的测量，很多行情都会被“小程序”误判，我写了十年小程序，也没有一款能精确的表达我想表达的思想，包括各种指标也都是有参数变量的，但是人眼的参数变量是更加精准的，所以人工筛选的准确率远大于指标，可以说一打眼就知道，通过程序测量就很可能是错的，所以才想要用AI的。
穷举不会限制智能，只要它对外沟通的接口，能够让学到新的知识，覆盖旧的知识就行了。
感受真实环境，输出信息影响真实环境，再次感受被自己影响后的环境。这个反馈结构能够形成闭环就达到了实现强人工智能的条件了。
chartgpt在文字上已经实现了这个闭环。就剩下以后开发出支持视觉、听觉的人工智能就可以取代人类
  也是
既然不足为外人道，是否其他人就没法探索出自己的赚钱的习惯与心态即经验了呢？当然可以，例如你是证券公司的，可以搜集赚钱的大批人的数据，从中用外界输入及序列特征处理能力的例如lstm或gpt模型挖掘出好的习惯与经验，然后做成只供极少人使用的咨询软件或自己用的自动炒股软件，它赚的概率就高些。
再不然就用历史数据进行强化学习，学习拟合出输入+序列状态对应的买卖点或概率急迫性，再以之指导操作，反复迭代，可有一定指导意义，在只有极少人有它的情况下，可以让极少人大概率长期能赚。
现实数据来强化学习则不太可行，虚拟的历史数据作用的场景，数据现成。
要有序列或多帧处理能力的神经网络，如果要多个型号适应，还应有条件输入能力。
因为说的是【箱】，所以默认是组装好的，封闭的，所以从传感角度思考了。帧让人联想到视频图，就好像是生产线，零件过一下监控。
因为齿轮设计有个特点，相互齿是互质的，运行时会均匀消耗所有齿。所以错误本身虽然是周期的，但并不能定位到哪个齿上。
哥我这是毕设。我应该着重于齿轮箱故障方面。我在网上找了个代码来检测故障的。但我感觉太少了
没有基本面的情况下，根本无法分辨这是哪家公司。即使知道了“进入超高温天气”这个信息，也无法判断后期的走势，因为从K线上分不出哪家公司是热饮，哪家公司是冷饮。 更极端的情况是，根本无法分辨，哪个K线是公司，哪个K线是用电脑随机生成的（无意义）K线。
这是求什么的哥 
你要诊断的值
那我有这个值是不是在用我找到的算法对这个值进行诊断就ok了吗
都有具体算法了还用什么神经网络？
创新、探索无限、工作就无限。只要创新力量调整到增加新岗位速度不低于AI增加力量占据已有岗位速度，人的岗位始终能保有足够数量。所以这其实是个管理问题，是可以通过调整、调度解决的问题。
重视创新创业的教育与激励机制，会有大量创新，即大量工作机会出现，可以使社会缺人而提高普通劳动者收入，而非令大量劳动者包括刷题精英都欠缺创新基础能力与实践体验，新增岗位速度赶不上科技进步带来的生产效率提高而减少已有岗位的速度，最后都只有选择去卷少量所谓白领岗而非创新创业。
我们培养刷题机应试比较方便，成本也不太高，管理上更容易，所以我们习惯了最近几十年的教育考试以笔试理论为主，恰好过去几十年从很落后到现在的发展仅需粗放快速，人口红利高，掩盖了创新实践能力与素质提升问题的不足，现在苦果来了，大船又不好掉头，利益方、习惯观念都不好改。
所以培养的精英，其实担不起创新之责，即使996，人多很多倍也进步相对慢，创新产生新岗位相对人口体量与旧岗位减速来说特别低。刷题精英更适合做买办搞拿来主义，原创则非其所长。象有些人口少教育重视实践创新的国家，人口如果有我们这样多，早就冲出地球，迎娶白富美，从此走向人生巅峰了。
一个简单习惯、策略可以赚钱，可自定保守程度，例如业绩差不多，相对较有业绩，跌过长期趋势或长期预期均值的一半肯定比跌得少的值得买，发现即买入，长期等待，等到翻倍即出货。这样基本大概率能赚而不亏。相信我，一个从开始入市到现在搞过多波从来没亏的人的话，当然，赚得也不多，最近几年18年始
年收益都没下过百分之十，18年到现在翻了翻的老股民的经验之谈
但是你没说数据，没说原理，硬让我们猜，就别挑剔各说各的。
那么你可以自设数据，定义正常数据和故障数据。为了真实性，可以从模拟齿轮开始。。
其实吧主说得挺到位。无故障和有故障就是两类数据。但具体是什么数据就不知道了。
要去找齿轮箱运行的整个生命周期数据，这个有点麻烦，只有生产时长时间记录运行状态。你或者从第三方获得数据。
可以用啊。齿轮箱我并不懂。但我觉得你这不是为了做齿轮箱，而是为了展现你的技术水平。所以不能用工业检测方法。
好滴哥  
应该是发现齿轮运行的故障哥 
唉，等上了高中之后就为理想而奋斗
只有行动起来才不会迷茫
可以学写程序。
我想进群
看私信
你没有回复内容
再看
